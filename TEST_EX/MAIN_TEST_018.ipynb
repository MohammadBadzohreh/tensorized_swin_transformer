{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "import os\n",
    "from Tensorized_components.patch_embedding  import Patch_Embedding     \n",
    "from Tensorized_components.w_msa_w_o_b_sign  import WindowMSA     \n",
    "from Tensorized_components.sh_wmsa_w_o_b_sign import ShiftedWindowMSA     \n",
    "from Tensorized_components.patch_merging  import TensorizedPatchMerging  \n",
    "from Tensorized_Layers.TCL_CHANGED import TCL_CHANGED   \n",
    "from Tensorized_Layers.TRL import TRL   \n",
    "from Utils.Accuracy_measures import topk_accuracy\n",
    "from Utils.TinyImageNet_loader import get_tinyimagenet_dataloaders\n",
    "from Utils.Num_parameter import count_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinBlock1(nn.Module):\n",
    "    \"\"\"\n",
    "    A class representing 'Block 1' in your Swin Transformer.\n",
    "    This captures the sequence of:\n",
    "        (1) Window MSA + residual\n",
    "        (2) TCL + residual\n",
    "        (3) Shifted Window MSA + residual\n",
    "        (4) TCL + residual\n",
    "    but only for the first blockâ€™s hyperparameters and submodules.\n",
    "    \"\"\"\n",
    "    def __init__(self, w_msa, sw_msa, tcl, embed_shape, dropout=0):\n",
    "        super(SwinBlock1, self).__init__()\n",
    "        # Typically each sub-layer has its own LayerNorm\n",
    "        self.norm1 = nn.LayerNorm(embed_shape)\n",
    "        self.norm2 = nn.LayerNorm(embed_shape)\n",
    "        self.norm3 = nn.LayerNorm(embed_shape)\n",
    "        self.norm4 = nn.LayerNorm(embed_shape)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # We pass in pre-built modules (WindowMSA, ShiftedWindowMSA, TCL)\n",
    "        self.w_msa = w_msa\n",
    "        self.sw_msa = sw_msa\n",
    "        self.tcl = tcl\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ----- First Window MSA + Residual -----\n",
    "        x_res = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.dropout(self.w_msa(x))\n",
    "        x = x + x_res\n",
    "\n",
    "        # ----- TCL + Residual -----\n",
    "        x_res = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.tcl(x)\n",
    "        x = x + x_res\n",
    "\n",
    "        # ----- Shifted Window MSA + Residual -----\n",
    "        x_res = x\n",
    "        x = self.norm3(x)\n",
    "        x = self.dropout(self.sw_msa(x))\n",
    "        x = x + x_res\n",
    "\n",
    "        # ----- TCL + Residual -----\n",
    "        x_res = x\n",
    "        x = self.norm4(x)\n",
    "        x = self.tcl(x)\n",
    "        x = x + x_res\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinBlock2(nn.Module):\n",
    "    def __init__(self, w_msa, sw_msa, tcl, embed_shape=(4,4,6), dropout=0):\n",
    "        super(SwinBlock2, self).__init__()\n",
    "        # LN layers\n",
    "        self.norm1 = nn.LayerNorm(embed_shape)\n",
    "        self.norm2 = nn.LayerNorm(embed_shape)\n",
    "        self.norm3 = nn.LayerNorm(embed_shape)\n",
    "        self.norm4 = nn.LayerNorm(embed_shape)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.w_msa = w_msa\n",
    "        self.sw_msa = sw_msa\n",
    "        self.tcl = tcl\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Window MSA\n",
    "        x_res = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.dropout(self.w_msa(x))\n",
    "        x = x + x_res\n",
    "\n",
    "        # TCL\n",
    "        x_res = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.tcl(x)\n",
    "        x = x + x_res\n",
    "\n",
    "        # Shifted Window MSA\n",
    "        x_res = x\n",
    "        x = self.norm3(x)\n",
    "        x = self.dropout(self.sw_msa(x))\n",
    "        x = x + x_res\n",
    "\n",
    "        # TCL\n",
    "        x_res = x\n",
    "        x = self.norm4(x)\n",
    "        x = self.tcl(x)\n",
    "        x = x + x_res\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinBlock3(nn.Module):\n",
    "    def __init__(self, w_msa, sw_msa, tcl, embed_shape=(4,4,12), dropout=0):\n",
    "        super(SwinBlock3, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(embed_shape)\n",
    "        self.norm2 = nn.LayerNorm(embed_shape)\n",
    "        self.norm3 = nn.LayerNorm(embed_shape)\n",
    "        self.norm4 = nn.LayerNorm(embed_shape)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.w_msa = w_msa\n",
    "        self.sw_msa = sw_msa\n",
    "        self.tcl = tcl\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_res = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.dropout(self.w_msa(x))\n",
    "        x = x + x_res\n",
    "\n",
    "        x_res = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.tcl(x)\n",
    "        x = x + x_res\n",
    "\n",
    "        x_res = x\n",
    "        x = self.norm3(x)\n",
    "        x = self.dropout(self.sw_msa(x))\n",
    "        x = x + x_res\n",
    "\n",
    "        x_res = x\n",
    "        x = self.norm4(x)\n",
    "        x = self.tcl(x)\n",
    "        x = x + x_res\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinBlock4(nn.Module):\n",
    "    def __init__(self, w_msa, sw_msa, tcl, embed_shape=(4,4,24), dropout=0):\n",
    "        super(SwinBlock4, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(embed_shape)\n",
    "        self.norm2 = nn.LayerNorm(embed_shape)\n",
    "        self.norm3 = nn.LayerNorm(embed_shape)\n",
    "        self.norm4 = nn.LayerNorm(embed_shape)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.w_msa = w_msa\n",
    "        self.sw_msa = sw_msa\n",
    "        self.tcl = tcl\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_res = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.dropout(self.w_msa(x))\n",
    "        x = x + x_res\n",
    "\n",
    "        x_res = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.tcl(x)\n",
    "        x = x + x_res\n",
    "\n",
    "        x_res = x\n",
    "        x = self.norm3(x)\n",
    "        x = self.dropout(self.sw_msa(x))\n",
    "        x = x + x_res\n",
    "\n",
    "        x_res = x\n",
    "        x = self.norm4(x)\n",
    "        x = self.tcl(x)\n",
    "        x = x + x_res\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 img_size=224,\n",
    "                 patch_size=4,\n",
    "                 in_chans=3,\n",
    "                 embed_shape=(4,4,12),\n",
    "                 bias=True,\n",
    "                 dropout=0,\n",
    "                 device=\"cuda\"):\n",
    "        super(SwinTransformer, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "        self.patch_embedding = Patch_Embedding(\n",
    "            img_size=img_size,\n",
    "            patch_size=patch_size,\n",
    "            in_chans=in_chans,\n",
    "            embed_shape=embed_shape,\n",
    "            bias=bias\n",
    "        )\n",
    "\n",
    "        # -------------------------------- block 1 --------------------------\n",
    "\n",
    "        self.w_msa_1 = WindowMSA(\n",
    "            window_size=7,\n",
    "            embed_dims=embed_shape,\n",
    "            rank_window=embed_shape,\n",
    "            head_factors=(1,2,3),\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        self.sw_msa_1 = ShiftedWindowMSA(\n",
    "            window_size=7,\n",
    "            embed_dims=embed_shape,\n",
    "            rank_window=embed_shape,\n",
    "            head_factors=(1,2,3),\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        self.tcl_1 = TCL_CHANGED(\n",
    "            input_size=(16, 56, 56, 4,4,12),\n",
    "            rank=(4,4,12),\n",
    "            ignore_modes=(0, 1, 2),\n",
    "            bias=bias,\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        self.block1_list = nn.ModuleList([\n",
    "            SwinBlock1(\n",
    "                w_msa=self.w_msa_1,\n",
    "                sw_msa=self.sw_msa_1,\n",
    "                tcl=self.tcl_1,\n",
    "                embed_shape=embed_shape,\n",
    "                dropout=dropout\n",
    "            )\n",
    "            for _ in range(2)\n",
    "        ])\n",
    "\n",
    "        # -------------------------------- block 2 --------------------------\n",
    "\n",
    "\n",
    "        self.patch_merging_1 = TensorizedPatchMerging(\n",
    "            input_size=(16, 56, 56, 4,4,12),\n",
    "            in_embed_shape=embed_shape,\n",
    "            out_embed_shape=(4,4,24),\n",
    "            bias=bias,\n",
    "            ignore_modes=(0, 1, 2),\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        self.w_msa_2 = WindowMSA(\n",
    "            window_size=7,\n",
    "            embed_dims=(4,4,24),\n",
    "            rank_window=(4,4,24),\n",
    "            head_factors=(1,2,6),\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        self.sw_msa_2 = ShiftedWindowMSA(\n",
    "            window_size=7,\n",
    "            embed_dims=(4,4,24),\n",
    "            rank_window=(4,4,24),\n",
    "            head_factors=(1,2,6),\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        self.tcl_2 = TCL_CHANGED(\n",
    "            input_size=(16, 28, 28, 4,4,24),\n",
    "            rank=(4,4,24),\n",
    "            ignore_modes=(0, 1, 2),\n",
    "            bias=bias,\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        # We repeat Block2 two times\n",
    "        self.block2_list = nn.ModuleList([\n",
    "            SwinBlock2(\n",
    "                w_msa=self.w_msa_2,\n",
    "                sw_msa=self.sw_msa_2,\n",
    "                tcl=self.tcl_2,\n",
    "                embed_shape=(4,4,24),  \n",
    "                dropout=dropout\n",
    "            )\n",
    "            for _ in range(2)\n",
    "        ])\n",
    "\n",
    "\n",
    "        # # -------------------------------- block 3 --------------------------\n",
    "\n",
    "        self.patch_merging_2 = TensorizedPatchMerging(\n",
    "            input_size=(16, 28, 28, 4,4,24),\n",
    "            in_embed_shape=(4,4,24),\n",
    "            out_embed_shape=(4,4,48),\n",
    "            bias=bias,\n",
    "            ignore_modes=(0, 1, 2),\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "\n",
    "        self.w_msa_3 = WindowMSA(\n",
    "            window_size=7,\n",
    "            embed_dims=(4,4,48),\n",
    "            rank_window=(4,4,48),\n",
    "            head_factors=(2,1,12),\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        self.sw_msa_3 = ShiftedWindowMSA(\n",
    "            window_size=7,\n",
    "            embed_dims=(4,4,48),\n",
    "            rank_window=(4,4,48),\n",
    "            head_factors=(2,1,12),\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        self.tcl_3 = TCL_CHANGED(\n",
    "            input_size=(16, 14, 14, 4,4,48),\n",
    "            rank=(4,4,48),\n",
    "            ignore_modes=(0, 1, 2),\n",
    "            bias=bias,\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        # Repeat Block3 6 times\n",
    "        self.block3_list = nn.ModuleList([\n",
    "            SwinBlock3(\n",
    "                w_msa=self.w_msa_3,\n",
    "                sw_msa=self.sw_msa_3,\n",
    "                tcl=self.tcl_3,\n",
    "                embed_shape=(4,4,48),\n",
    "                dropout=dropout\n",
    "            )\n",
    "            for _ in range(18)\n",
    "        ])\n",
    "\n",
    "        # # # -------------------------------- block 4 --------------------------\n",
    "\n",
    "        self.patch_merging_3 = TensorizedPatchMerging(\n",
    "            input_size=(16, 14, 14, 4,4,48),\n",
    "            in_embed_shape=(4,4,48),\n",
    "            out_embed_shape=(4,4,96),\n",
    "            bias=bias,\n",
    "            ignore_modes=(0, 1, 2),\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        self.w_msa_4 = WindowMSA(\n",
    "            window_size=7,\n",
    "            embed_dims=(4,4,96),\n",
    "            rank_window=(4,4,96),\n",
    "            head_factors=(2,1,24),\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        self.sw_msa_4 = ShiftedWindowMSA(\n",
    "            window_size=7,\n",
    "            embed_dims=(4,4,96),\n",
    "            rank_window=(4,4,96),\n",
    "            head_factors=(2,1,24),\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        self.tcl_4 = TCL_CHANGED(\n",
    "            input_size=(16, 7, 7, 4,4,96),\n",
    "            rank=(4,4,96),\n",
    "            ignore_modes=(0, 1, 2),\n",
    "            bias=bias,\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "\n",
    "        self.block4_list = nn.ModuleList([\n",
    "            SwinBlock4(\n",
    "                w_msa=self.w_msa_4,\n",
    "                sw_msa=self.sw_msa_4,\n",
    "                tcl=self.tcl_4,\n",
    "                embed_shape=(4,4,96),\n",
    "                dropout=dropout\n",
    "            )\n",
    "            for _ in range(2)\n",
    "        ])\n",
    "\n",
    "        # -------------------------------- classifier --------------------------\n",
    "\n",
    "    \n",
    "\n",
    "        self.classifier = TRL(input_size=(16,4,4,96),\n",
    "                            output=(200,),\n",
    "                            rank=(4,4,96,200),\n",
    "                            ignore_modes=(0,),\n",
    "                            bias=bias,\n",
    "                            device=self.device) \n",
    "        \n",
    "\n",
    "        # positoin embedding\n",
    "\n",
    "\n",
    "        self.pos_embedding = nn.Parameter(\n",
    "            torch.randn(1,\n",
    "                        56,\n",
    "                        56,\n",
    "                        4,\n",
    "                        4,\n",
    "                        12,\n",
    "                        device = self.device\n",
    "                        ), requires_grad=True)\n",
    "\n",
    "    def forward(self, x):\n",
    " \n",
    "\n",
    "        x = self.patch_embedding(x)\n",
    "\n",
    "        x += self.pos_embedding\n",
    "\n",
    "        for i, blk in enumerate(self.block1_list, 1):\n",
    "            x = blk(x)\n",
    "\n",
    "\n",
    "        x = self.patch_merging_1(x)\n",
    "\n",
    "\n",
    "\n",
    "        for i, blk in enumerate(self.block2_list, 1):\n",
    "            x = blk(x)\n",
    "\n",
    "\n",
    "        x = self.patch_merging_2(x)\n",
    "\n",
    "        for i, blk in enumerate(self.block3_list, 1):\n",
    "            x = blk(x)\n",
    "\n",
    "\n",
    "        x = self.patch_merging_3(x)\n",
    "\n",
    "\n",
    "        for i, blk in enumerate(self.block4_list, 1):\n",
    "            x = blk(x)\n",
    "\n",
    "\n",
    "        x = x.mean(dim=(1, 2))\n",
    "\n",
    "        output = self.classifier(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is set to : cuda\n"
     ]
    }
   ],
   "source": [
    "# Setup the device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'\n",
    "print(f'Device is set to : {device}')\n",
    "\n",
    "# Configs\n",
    "\n",
    "TEST_ID = 'Test_ID015'\n",
    "batch_size = 16\n",
    "n_epoch = 400\n",
    "image_size = 224\n",
    "\n",
    "model = SwinTransformer(img_size=224,patch_size=4,in_chans=3,embed_shape=(4,4,12),bias=True,device=device).to(device)\n",
    "\n",
    "\n",
    "# Set up the transforms and train/test loaders\n",
    "\n",
    "tiny_transform_train = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Resize((image_size, image_size)), \n",
    "        transforms.RandomCrop(image_size, padding=5),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])\n",
    "tiny_transform_val = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])\n",
    "tiny_transform_test = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])\n",
    "\n",
    "\n",
    "train_loader, val_loader , test_loader = get_tinyimagenet_dataloaders(\n",
    "                                                    data_dir = '../datasets',\n",
    "                                                    transform_train=tiny_transform_train,\n",
    "                                                    transform_val=tiny_transform_val,\n",
    "                                                    transform_test=tiny_transform_test,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    image_size=image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Model has 1257400 parameters\n",
      "Training for 400 epochs\n",
      "\n",
      "Train epoch 1: top1=0.014329999685287476%, top2=0.027249999344348907%, top3=0.03926999866962433%, top4=0.05104999989271164%, top5=0.06216000020503998%, loss=0.3216049895524979, time=1427.577926158905s\n",
      "Train epoch 2: top1=0.054829999804496765%, top2=0.09358000010251999%, top3=0.12532000243663788%, top4=0.1531900018453598%, top5=0.17734000086784363%, loss=0.2935098344540596, time=1430.8146991729736s\n",
      "Train epoch 3: top1=0.0968099981546402%, top2=0.15392999351024628%, top3=0.19735999405384064%, top4=0.23399999737739563%, top5=0.2640700042247772%, loss=0.2723195094704628, time=1430.4225416183472s\n",
      "Train epoch 4: top1=0.1351199895143509%, top2=0.20568999648094177%, top3=0.2570199966430664%, top4=0.29940998554229736%, top5=0.3350200057029724%, loss=0.25477375359535215, time=1429.7205855846405s\n",
      "Train epoch 5: top1=0.16658999025821686%, top2=0.24795998632907867%, top3=0.3037700057029724%, top4=0.3485899865627289%, top5=0.38593000173568726%, loss=0.24088867822885512, time=1429.4300744533539s\n",
      "Train epoch 6: top1=0.1903200000524521%, top2=0.2767399847507477%, top3=0.3365100026130676%, top4=0.382860004901886%, top5=0.42159998416900635%, loss=0.2315247048974037, time=1429.2327291965485s\n",
      "Train epoch 7: top1=0.20906999707221985%, top2=0.3021099865436554%, top3=0.3644299805164337%, top4=0.4123799800872803%, top5=0.45124000310897827%, loss=0.22373599078416825, time=1430.0934972763062s\n",
      "Train epoch 8: top1=0.22784999012947083%, top2=0.32519999146461487%, top3=0.3894699811935425%, top4=0.4383299946784973%, top5=0.4781099855899811%, loss=0.21651287938714028, time=1430.2431166172028s\n",
      "Train epoch 9: top1=0.24504999816417694%, top2=0.3470799922943115%, top3=0.4138000011444092%, top4=0.46316999197006226%, top5=0.5020899772644043%, loss=0.2098668933725357, time=1430.762701034546s\n",
      "Train epoch 10: top1=0.26225000619888306%, top2=0.36778998374938965%, top3=0.43372997641563416%, top4=0.48144999146461487%, top5=0.5218299627304077%, loss=0.20396162984490396, time=1429.5264427661896s\n",
      "Train epoch 11: top1=0.2750699818134308%, top2=0.38266998529434204%, top3=0.4505699872970581%, top4=0.5000799894332886%, top5=0.5392999649047852%, loss=0.1989656043922901, time=1430.6171169281006s\n",
      "Train epoch 12: top1=0.28950998187065125%, top2=0.39812999963760376%, top3=0.4652799963951111%, top4=0.5149999856948853%, top5=0.5539199709892273%, loss=0.19430176117777825, time=1432.8046555519104s\n",
      "Train epoch 13: top1=0.3013499975204468%, top2=0.4138999879360199%, top3=0.48326998949050903%, top4=0.5319200158119202%, top5=0.5695799589157104%, loss=0.18995213032245636, time=1431.8185923099518s\n",
      "Train epoch 14: top1=0.31169000267982483%, top2=0.42462000250816345%, top3=0.494299978017807%, top4=0.5436899662017822%, top5=0.5819000005722046%, loss=0.18626586091399192, time=1430.8876616954803s\n",
      "Train epoch 15: top1=0.32165998220443726%, top2=0.4353399872779846%, top3=0.5057199597358704%, top4=0.5556699633598328%, top5=0.5949699878692627%, loss=0.1825369061934948, time=1432.7331721782684s\n",
      "Train epoch 16: top1=0.33267998695373535%, top2=0.44821998476982117%, top3=0.5179699659347534%, top4=0.5680699944496155%, top5=0.6064199805259705%, loss=0.1788835389471054, time=1430.2714574337006s\n",
      "Train epoch 17: top1=0.3432599902153015%, top2=0.45989999175071716%, top3=0.5303599834442139%, top4=0.5791000127792358%, top5=0.6170799732208252%, loss=0.17545111381411552, time=1427.7111477851868s\n",
      "Train epoch 18: top1=0.35062000155448914%, top2=0.4693499803543091%, top3=0.53916996717453%, top4=0.5887699723243713%, top5=0.6263200044631958%, loss=0.17248830944001675, time=1430.8665895462036s\n",
      "Train epoch 19: top1=0.3596400022506714%, top2=0.4784799814224243%, top3=0.5477100014686584%, top4=0.5971599817276001%, top5=0.6353099942207336%, loss=0.16947264236211776, time=1429.8947761058807s\n",
      "Train epoch 20: top1=0.36901000142097473%, top2=0.48736998438835144%, top3=0.5572099685668945%, top4=0.6061800122261047%, top5=0.6430099606513977%, loss=0.16672684116125105, time=1429.9545669555664s\n",
      "Train epoch 21: top1=0.37581998109817505%, top2=0.4976999759674072%, top3=0.5687999725341797%, top4=0.6166599988937378%, top5=0.6539799571037292%, loss=0.16383473669052123, time=1430.3845179080963s\n",
      "Train epoch 22: top1=0.38352999091148376%, top2=0.5054000020027161%, top3=0.5759899616241455%, top4=0.6246100068092346%, top5=0.6617599725723267%, loss=0.1611978436553478, time=1429.1067881584167s\n",
      "Train epoch 23: top1=0.39003998041152954%, top2=0.5133599638938904%, top3=0.585129976272583%, top4=0.6326599717140198%, top5=0.6693300008773804%, loss=0.15895283399283885, time=1430.6512243747711s\n",
      "Train epoch 24: top1=0.39958998560905457%, top2=0.5241000056266785%, top3=0.5929200053215027%, top4=0.6415799856185913%, top5=0.6787499785423279%, loss=0.15593226695239543, time=1430.584238767624s\n",
      "Train epoch 25: top1=0.40626999735832214%, top2=0.5299299955368042%, top3=0.6015499830245972%, top4=0.6498599648475647%, top5=0.6857999563217163%, loss=0.15394388930618763, time=1431.4960978031158s\n",
      "Train epoch 26: top1=0.41384997963905334%, top2=0.538349986076355%, top3=0.6077600121498108%, top4=0.6560999751091003%, top5=0.6929399967193604%, loss=0.15146903469622136, time=1429.9564864635468s\n",
      "Train epoch 27: top1=0.4211699962615967%, top2=0.5440799593925476%, top3=0.6148999929428101%, top4=0.6636099815368652%, top5=0.6992799639701843%, loss=0.1490317948102951, time=1416.5599792003632s\n",
      "Train epoch 28: top1=0.426859974861145%, top2=0.5526099801063538%, top3=0.6227999925613403%, top4=0.6703000068664551%, top5=0.7058699727058411%, loss=0.14704175797700883, time=1403.5579929351807s\n",
      "Train epoch 29: top1=0.43375998735427856%, top2=0.5604900121688843%, top3=0.6308199763298035%, top4=0.6784499883651733%, top5=0.7136699557304382%, loss=0.1445908374285698, time=1403.4704985618591s\n",
      "Train epoch 30: top1=0.4389899969100952%, top2=0.5651000142097473%, top3=0.6363199949264526%, top4=0.6830999851226807%, top5=0.7176100015640259%, loss=0.1427350028926134, time=1402.8652141094208s\n",
      "Train epoch 31: top1=0.4448300004005432%, top2=0.5742799639701843%, top3=0.6450299620628357%, top4=0.6914799809455872%, top5=0.7258699536323547%, loss=0.14052482831239702, time=1403.2211782932281s\n",
      "Train epoch 32: top1=0.45086997747421265%, top2=0.5803799629211426%, top3=0.6508499979972839%, top4=0.6974299550056458%, top5=0.7321299910545349%, loss=0.1385584863346815, time=1404.0744442939758s\n",
      "Train epoch 33: top1=0.45837998390197754%, top2=0.5880199670791626%, top3=0.6576600074768066%, top4=0.7041299939155579%, top5=0.7378999590873718%, loss=0.13636407667577266, time=1404.1601493358612s\n",
      "Train epoch 34: top1=0.46417999267578125%, top2=0.5931199789047241%, top3=0.6640799641609192%, top4=0.7101699709892273%, top5=0.7437099814414978%, loss=0.13435043035686017, time=1403.1336889266968s\n",
      "Train epoch 35: top1=0.46945998072624207%, top2=0.5988099575042725%, top3=0.6699900031089783%, top4=0.7162100076675415%, top5=0.7496399879455566%, loss=0.13255527000129222, time=1401.8054566383362s\n",
      "Train epoch 36: top1=0.4772000014781952%, top2=0.6060900092124939%, top3=0.67631995677948%, top4=0.7226899862289429%, top5=0.7551199793815613%, loss=0.13067317041873933, time=1401.2355256080627s\n",
      "Train epoch 37: top1=0.4803699851036072%, top2=0.6096099615097046%, top3=0.679099977016449%, top4=0.7250799536705017%, top5=0.7592200040817261%, loss=0.12913571809768676, time=1403.071615934372s\n",
      "Train epoch 38: top1=0.48659998178482056%, top2=0.6148599982261658%, top3=0.6854900121688843%, top4=0.7310499548912048%, top5=0.7646899819374084%, loss=0.1273602324450016, time=1402.0025510787964s\n",
      "Train epoch 39: top1=0.4943999946117401%, top2=0.6245999932289124%, top3=0.6936599612236023%, top4=0.7398799657821655%, top5=0.7717799544334412%, loss=0.12513624176740645, time=1400.6298925876617s\n",
      "Train epoch 40: top1=0.49723997712135315%, top2=0.6285200119018555%, top3=0.696940004825592%, top4=0.7432399988174438%, top5=0.774619996547699%, loss=0.12369861486554146, time=1401.7901289463043s\n",
      "Train epoch 41: top1=0.5036599636077881%, top2=0.6340399980545044%, top3=0.7023499608039856%, top4=0.747189998626709%, top5=0.779449999332428%, loss=0.12194040323555469, time=1401.6162049770355s\n",
      "Train epoch 42: top1=0.5102899670600891%, top2=0.6417099833488464%, top3=0.7102800011634827%, top4=0.7541799545288086%, top5=0.7859899997711182%, loss=0.12018803240418434, time=1401.9562292099s\n",
      "Train epoch 43: top1=0.5120599865913391%, top2=0.6442399621009827%, top3=0.7132999897003174%, top4=0.7570199966430664%, top5=0.78889000415802%, loss=0.11880230327606202, time=1402.4604232311249s\n",
      "Train epoch 44: top1=0.5205900073051453%, top2=0.6516599655151367%, top3=0.7190999984741211%, top4=0.7643699645996094%, top5=0.7957899570465088%, loss=0.11649277543842793, time=1401.779888868332s\n",
      "Train epoch 45: top1=0.5242099761962891%, top2=0.6565600037574768%, top3=0.724839985370636%, top4=0.7684099674224854%, top5=0.799519956111908%, loss=0.11512360951662064, time=1402.2080373764038s\n",
      "Train epoch 46: top1=0.5275999903678894%, top2=0.6608399748802185%, top3=0.7280399799346924%, top4=0.7720299959182739%, top5=0.802649974822998%, loss=0.11367646751701832, time=1401.3834235668182s\n",
      "Train epoch 47: top1=0.5325300097465515%, top2=0.6649599671363831%, top3=0.7342699766159058%, top4=0.7774099707603455%, top5=0.8090099692344666%, loss=0.11196957014322281, time=1401.6630108356476s\n",
      "Train epoch 48: top1=0.539139986038208%, top2=0.6728000044822693%, top3=0.7421900033950806%, top4=0.7846699953079224%, top5=0.8142499923706055%, loss=0.11018140492528677, time=1401.3207349777222s\n",
      "Train epoch 49: top1=0.5448499917984009%, top2=0.6768199801445007%, top3=0.7439900040626526%, top4=0.7864599823951721%, top5=0.8165099620819092%, loss=0.10889433803200722, time=1401.8229212760925s\n",
      "Train epoch 50: top1=0.5479400157928467%, top2=0.6824899911880493%, top3=0.7490400075912476%, top4=0.7925300002098083%, top5=0.8226400017738342%, loss=0.10716003519833088, time=1400.2867863178253s\n",
      "Train epoch 51: top1=0.5539799928665161%, top2=0.6868399977684021%, top3=0.7549399733543396%, top4=0.7978000044822693%, top5=0.8264699578285217%, loss=0.10567035843461751, time=1399.3179867267609s\n",
      "Train epoch 52: top1=0.5596699714660645%, top2=0.693340003490448%, top3=0.7611199617385864%, top4=0.8018400073051453%, top5=0.8289799690246582%, loss=0.10430454273819924, time=1403.1220207214355s\n",
      "Train epoch 53: top1=0.5629900097846985%, top2=0.6959099769592285%, top3=0.7635299563407898%, top4=0.8052799701690674%, top5=0.8336199522018433%, loss=0.10295766956403851, time=1401.896996498108s\n",
      "Train epoch 54: top1=0.5688700079917908%, top2=0.7031899690628052%, top3=0.7683299779891968%, top4=0.8095499873161316%, top5=0.8387799859046936%, loss=0.10121253221064806, time=1400.937481880188s\n",
      "Train epoch 55: top1=0.5724899768829346%, top2=0.706119954586029%, top3=0.7728700041770935%, top4=0.8138699531555176%, top5=0.8413099646568298%, loss=0.0999145367115736, time=1401.3304901123047s\n",
      "Train epoch 56: top1=0.5775399804115295%, top2=0.7100799679756165%, top3=0.7773500084877014%, top4=0.8187099695205688%, top5=0.8470199704170227%, loss=0.09852967009663582, time=1400.4143176078796s\n",
      "Train epoch 57: top1=0.5818799734115601%, top2=0.7164499759674072%, top3=0.781059980392456%, top4=0.8230099678039551%, top5=0.8502299785614014%, loss=0.0970530859580636, time=1402.8300063610077s\n",
      "Train epoch 58: top1=0.5853700041770935%, top2=0.719980001449585%, top3=0.7850099802017212%, top4=0.8256399631500244%, top5=0.8531299829483032%, loss=0.09585596891403199, time=1403.0944774150848s\n",
      "Train epoch 59: top1=0.5894699692726135%, top2=0.7252900004386902%, top3=0.7891599535942078%, top4=0.829069972038269%, top5=0.8563599586486816%, loss=0.09467997579187155, time=1402.6627650260925s\n",
      "Train epoch 60: top1=0.5954499840736389%, top2=0.7295999526977539%, top3=0.7929399609565735%, top4=0.8338099718093872%, top5=0.8612200021743774%, loss=0.09317105960726738, time=1402.6179807186127s\n",
      "Train epoch 61: top1=0.5982599854469299%, top2=0.7328799962997437%, top3=0.7973600029945374%, top4=0.8372899889945984%, top5=0.8637799620628357%, loss=0.09214444105744361, time=1401.9871144294739s\n",
      "Train epoch 62: top1=0.6051899790763855%, top2=0.7392999529838562%, top3=0.8033599853515625%, top4=0.8413499593734741%, top5=0.8668400049209595%, loss=0.0904237575994432, time=1402.9001643657684s\n",
      "Train epoch 63: top1=0.6085799932479858%, top2=0.7415499687194824%, top3=0.8047999739646912%, top4=0.8431199789047241%, top5=0.8695600032806396%, loss=0.08948793743640185, time=1403.5004365444183s\n",
      "Train epoch 64: top1=0.6099900007247925%, top2=0.7432699799537659%, top3=0.8070299625396729%, top4=0.8454099893569946%, top5=0.8715699911117554%, loss=0.08855126193553209, time=1404.034182548523s\n",
      "Train epoch 65: top1=0.613349974155426%, top2=0.7481799721717834%, top3=0.8107900023460388%, top4=0.8489899635314941%, top5=0.8748899698257446%, loss=0.08766569017887116, time=1403.474216222763s\n",
      "Train epoch 66: top1=0.620389997959137%, top2=0.7542699575424194%, top3=0.8167099952697754%, top4=0.8551899790763855%, top5=0.8794800043106079%, loss=0.08606995252758265, time=1402.9346051216125s\n",
      "Train epoch 67: top1=0.6237800121307373%, top2=0.7552099823951721%, top3=0.8183099627494812%, top4=0.8559499979019165%, top5=0.8807899951934814%, loss=0.08514849317610264, time=1402.5977470874786s\n",
      "Train epoch 68: top1=0.6260299682617188%, top2=0.7602599859237671%, top3=0.821940004825592%, top4=0.8597399592399597%, top5=0.8848399519920349%, loss=0.08373260160043836, time=1403.587617635727s\n",
      "Train epoch 69: top1=0.6293100118637085%, top2=0.7627899646759033%, top3=0.8238199949264526%, top4=0.8607800006866455%, top5=0.8858999609947205%, loss=0.08317741435572505, time=1403.478712797165s\n",
      "Train epoch 70: top1=0.6309700012207031%, top2=0.7653599977493286%, top3=0.8268499970436096%, top4=0.8634199500083923%, top5=0.8884599804878235%, loss=0.08226517107017338, time=1403.1187980175018s\n",
      "Train epoch 71: top1=0.6359599828720093%, top2=0.7694000005722046%, top3=0.8309499621391296%, top4=0.8681399822235107%, top5=0.8922799825668335%, loss=0.08096925514146686, time=1404.256626367569s\n",
      "Train epoch 72: top1=0.6411899924278259%, top2=0.7730099558830261%, top3=0.8344799876213074%, top4=0.8697399497032166%, top5=0.8939899802207947%, loss=0.07984648073881864, time=1402.3170218467712s\n",
      "Train epoch 73: top1=0.64301997423172%, top2=0.7753899693489075%, top3=0.8373000025749207%, top4=0.8722899556159973%, top5=0.8961099982261658%, loss=0.07922769656777381, time=1403.2450850009918s\n",
      "Train epoch 74: top1=0.6467799544334412%, top2=0.7780199646949768%, top3=0.8383899927139282%, top4=0.8735299706459045%, top5=0.8974300026893616%, loss=0.07828104989230633, time=1404.6644990444183s\n",
      "Train epoch 75: top1=0.6480299830436707%, top2=0.7789899706840515%, top3=0.8398099541664124%, top4=0.8756299614906311%, top5=0.8985499739646912%, loss=0.07798656790345908, time=1403.432446718216s\n",
      "Train epoch 76: top1=0.6505100131034851%, top2=0.7838900089263916%, top3=0.8434499502182007%, top4=0.8786399960517883%, top5=0.9018799662590027%, loss=0.07697460706189274, time=1402.1718964576721s\n",
      "Train epoch 77: top1=0.6535899639129639%, top2=0.7855599522590637%, top3=0.8451299667358398%, top4=0.8797299861907959%, top5=0.9025099873542786%, loss=0.07637814454913139, time=1402.3184161186218s\n",
      "Train epoch 78: top1=0.6573100090026855%, top2=0.7880799770355225%, top3=0.8487899899482727%, top4=0.8825500011444092%, top5=0.9051100015640259%, loss=0.0755817585529387, time=1402.7120940685272s\n",
      "Train epoch 79: top1=0.6592999696731567%, top2=0.7909799814224243%, top3=0.8510599732398987%, top4=0.8864399790763855%, top5=0.9084499478340149%, loss=0.0746927821843326, time=1403.0795245170593s\n",
      "Train epoch 80: top1=0.6619600057601929%, top2=0.794219970703125%, top3=0.8525599837303162%, top4=0.8852300047874451%, top5=0.908079981803894%, loss=0.0739040582384169, time=1402.007866859436s\n",
      "Train epoch 81: top1=0.6649099588394165%, top2=0.7968499660491943%, top3=0.8552299737930298%, top4=0.8884299993515015%, top5=0.9102099537849426%, loss=0.07322682611137629, time=1402.229418516159s\n",
      "Train epoch 82: top1=0.6682899594306946%, top2=0.8000199794769287%, top3=0.8574499487876892%, top4=0.8910599946975708%, top5=0.9127500057220459%, loss=0.07235440869629384, time=1403.5865647792816s\n",
      "Train epoch 83: top1=0.6709100008010864%, top2=0.802109956741333%, top3=0.8583399653434753%, top4=0.8918699622154236%, top5=0.9131799936294556%, loss=0.0718733468799293, time=1399.236020565033s\n",
      "Train epoch 84: top1=0.6745100021362305%, top2=0.8044899702072144%, top3=0.8621699810028076%, top4=0.894599974155426%, top5=0.9164800047874451%, loss=0.07080432002976536, time=1421.4694769382477s\n",
      "Train epoch 85: top1=0.6753299832344055%, top2=0.8050000071525574%, top3=0.8626799583435059%, top4=0.8973000049591064%, top5=0.9183099865913391%, loss=0.07026920414268971, time=1424.300972700119s\n",
      "Train epoch 86: top1=0.6782400012016296%, top2=0.8088600039482117%, top3=0.8667199611663818%, top4=0.8985599875450134%, top5=0.9196999669075012%, loss=0.06935642712160944, time=1424.6928429603577s\n",
      "Train epoch 87: top1=0.6812199950218201%, top2=0.8098999857902527%, top3=0.8659899830818176%, top4=0.8990199565887451%, top5=0.9192900061607361%, loss=0.06907472077593207, time=1424.8066787719727s\n",
      "Train epoch 88: top1=0.6807699799537659%, top2=0.8115999698638916%, top3=0.8684499859809875%, top4=0.9000799655914307%, top5=0.9211499691009521%, loss=0.06863058805808425, time=1424.0976560115814s\n",
      "Train epoch 89: top1=0.6841599941253662%, top2=0.8151499629020691%, top3=0.8721099495887756%, top4=0.9040299654006958%, top5=0.9243099689483643%, loss=0.06766043962568044, time=1423.8872065544128s\n",
      "Train epoch 90: top1=0.6862300038337708%, top2=0.8151199817657471%, top3=0.871969997882843%, top4=0.903689980506897%, top5=0.9243099689483643%, loss=0.06736933583021164, time=1425.2796702384949s\n",
      "Train epoch 91: top1=0.6899399757385254%, top2=0.8187800049781799%, top3=0.8733199834823608%, top4=0.9042800068855286%, top5=0.9244099855422974%, loss=0.06657295776113868, time=1424.5257856845856s\n",
      "Train epoch 92: top1=0.6911500096321106%, top2=0.8199899792671204%, top3=0.8749899864196777%, top4=0.9062699675559998%, top5=0.9262399673461914%, loss=0.06605018252566457, time=1423.990555524826s\n",
      "Train epoch 93: top1=0.6926999688148499%, top2=0.8224299550056458%, top3=0.8772299885749817%, top4=0.9079999923706055%, top5=0.9277399778366089%, loss=0.06572820389531553, time=1390.5967230796814s\n",
      "Train epoch 94: top1=0.6941399574279785%, top2=0.8219599723815918%, top3=0.8777299523353577%, top4=0.9088999629020691%, top5=0.9294499754905701%, loss=0.06531863019369542, time=1376.5734968185425s\n",
      "Train epoch 95: top1=0.6974700093269348%, top2=0.8263199925422668%, top3=0.8803899884223938%, top4=0.9115299582481384%, top5=0.9309499859809875%, loss=0.06425277705773712, time=1377.6847393512726s\n",
      "Train epoch 96: top1=0.6992999911308289%, top2=0.8275600075721741%, top3=0.88291996717453%, top4=0.9139999747276306%, top5=0.9330599904060364%, loss=0.0638031406737864, time=1376.271353006363s\n",
      "Train epoch 97: top1=0.7030099630355835%, top2=0.8307799696922302%, top3=0.8841300010681152%, top4=0.9137899875640869%, top5=0.9322099685668945%, loss=0.06334280600637197, time=1377.327329158783s\n",
      "Train epoch 98: top1=0.7001299858093262%, top2=0.829039990901947%, top3=0.883359968662262%, top4=0.9132300019264221%, top5=0.9334099888801575%, loss=0.0635532505043596, time=1377.5542833805084s\n",
      "Train epoch 99: top1=0.7054299712181091%, top2=0.8330499529838562%, top3=0.8857799768447876%, top4=0.9158999919891357%, top5=0.9344300031661987%, loss=0.062456449606344104, time=1380.2402288913727s\n",
      "Train epoch 100: top1=0.7055599689483643%, top2=0.8332899808883667%, top3=0.8872399926185608%, top4=0.9162399768829346%, top5=0.9351799488067627%, loss=0.06210443654641509, time=1378.5314722061157s\n",
      "Train epoch 101: top1=0.7096199989318848%, top2=0.8359999656677246%, top3=0.8891399502754211%, top4=0.9183599948883057%, top5=0.9362599849700928%, loss=0.06146240649774671, time=1377.8235847949982s\n",
      "Train epoch 102: top1=0.7100299596786499%, top2=0.8365699648857117%, top3=0.8896099925041199%, top4=0.9185299873352051%, top5=0.9381399750709534%, loss=0.06108598333053291, time=1378.375742673874s\n",
      "Train epoch 103: top1=0.7143799662590027%, top2=0.8385499715805054%, top3=0.891819953918457%, top4=0.9211999773979187%, top5=0.9392099976539612%, loss=0.06037845175668597, time=1378.9857959747314s\n",
      "Train epoch 104: top1=0.7129600048065186%, top2=0.8385599851608276%, top3=0.8927800059318542%, top4=0.9214099645614624%, top5=0.9389899969100952%, loss=0.060251841035857796, time=1377.2514595985413s\n",
      "Train epoch 105: top1=0.7152799963951111%, top2=0.8424599766731262%, top3=0.8955699801445007%, top4=0.9237499833106995%, top5=0.9406999945640564%, loss=0.05979001812189817, time=1377.380877494812s\n",
      "Train epoch 106: top1=0.7173399925231934%, top2=0.8433600068092346%, top3=0.894629955291748%, top4=0.9228499531745911%, top5=0.9406499862670898%, loss=0.05955054601192474, time=1376.7060527801514s\n",
      "Train epoch 107: top1=0.7153599858283997%, top2=0.8431499600410461%, top3=0.895799994468689%, top4=0.9246199727058411%, top5=0.9425199627876282%, loss=0.05927379265010357, time=1375.1240389347076s\n",
      "Train epoch 108: top1=0.7212799787521362%, top2=0.8446499705314636%, top3=0.896619975566864%, top4=0.9249699711799622%, top5=0.9423999786376953%, loss=0.05845938109010458, time=1378.6397433280945s\n",
      "Train epoch 109: top1=0.7245699763298035%, top2=0.8468799591064453%, top3=0.8983999490737915%, top4=0.9259899854660034%, top5=0.94336998462677%, loss=0.05799197398632765, time=1378.2203674316406s\n",
      "Train epoch 110: top1=0.7239999771118164%, top2=0.8480299711227417%, top3=0.8997099995613098%, top4=0.9269199967384338%, top5=0.94364994764328%, loss=0.057781494085080924, time=1379.4445724487305s\n",
      "Train epoch 111: top1=0.7253299951553345%, top2=0.8504700064659119%, top3=0.9013499617576599%, top4=0.9283799529075623%, top5=0.9447299838066101%, loss=0.05729749269623309, time=1377.2076380252838s\n",
      "Train epoch 112: top1=0.7257099747657776%, top2=0.8497299551963806%, top3=0.9003899693489075%, top4=0.9280099868774414%, top5=0.945639967918396%, loss=0.05733007010780275, time=1377.583351135254s\n",
      "Train epoch 113: top1=0.7285899519920349%, top2=0.8513199687004089%, top3=0.9019100069999695%, top4=0.9300899505615234%, top5=0.946679949760437%, loss=0.056686876818090676, time=1377.4040348529816s\n",
      "Train epoch 114: top1=0.7271299958229065%, top2=0.8530600070953369%, top3=0.9029499888420105%, top4=0.930709958076477%, top5=0.9471299648284912%, loss=0.056482336129024625, time=1377.4228341579437s\n",
      "Train epoch 115: top1=0.7303199768066406%, top2=0.8527500033378601%, top3=0.9033599495887756%, top4=0.9313899874687195%, top5=0.9475699663162231%, loss=0.05607019578546286, time=1378.025800228119s\n",
      "Train epoch 116: top1=0.7330099940299988%, top2=0.8553799986839294%, top3=0.9055699706077576%, top4=0.9322899580001831%, top5=0.9490799903869629%, loss=0.05553544029742479, time=1378.7279198169708s\n",
      "Train epoch 117: top1=0.735040009021759%, top2=0.8565499782562256%, top3=0.9064099788665771%, top4=0.9332099556922913%, top5=0.9489299654960632%, loss=0.055103576049506664, time=1376.7809972763062s\n",
      "Train epoch 118: top1=0.7359899878501892%, top2=0.8581500053405762%, top3=0.9084999561309814%, top4=0.9347099661827087%, top5=0.9512199759483337%, loss=0.05490830545011908, time=1379.7770144939423s\n",
      "Train epoch 119: top1=0.7360299825668335%, top2=0.8605599999427795%, top3=0.9083899855613708%, top4=0.9349299669265747%, top5=0.9508299827575684%, loss=0.0545844569773227, time=1376.0999207496643s\n",
      "Train epoch 120: top1=0.7391200065612793%, top2=0.8609299659729004%, top3=0.9100399613380432%, top4=0.9359299540519714%, top5=0.9523599743843079%, loss=0.05415253849595785, time=1377.9516024589539s\n",
      "Train epoch 121: top1=0.7391999959945679%, top2=0.8620799779891968%, top3=0.910819947719574%, top4=0.9362899661064148%, top5=0.952019989490509%, loss=0.05378410152014345, time=1377.0600695610046s\n",
      "Train epoch 122: top1=0.7415800094604492%, top2=0.8622999787330627%, top3=0.910129964351654%, top4=0.9365399479866028%, top5=0.9519199728965759%, loss=0.05359363063339144, time=1376.9165761470795s\n",
      "Train epoch 123: top1=0.7420699596405029%, top2=0.8630899786949158%, top3=0.9112699627876282%, top4=0.936959981918335%, top5=0.9521299600601196%, loss=0.05341983857683837, time=1377.8564319610596s\n",
      "Train epoch 124: top1=0.7436400055885315%, top2=0.8642899990081787%, top3=0.9122099876403809%, top4=0.9380699992179871%, top5=0.9532600045204163%, loss=0.0529975775450468, time=1377.830066204071s\n",
      "Train epoch 125: top1=0.7458499670028687%, top2=0.8664900064468384%, top3=0.914110004901886%, top4=0.9392399787902832%, top5=0.9549399614334106%, loss=0.052463984351307155, time=1376.884417772293s\n",
      "Train epoch 126: top1=0.7458800077438354%, top2=0.8667199611663818%, top3=0.9138299822807312%, top4=0.9394599795341492%, top5=0.9549499750137329%, loss=0.05248163624867797, time=1376.013846874237s\n",
      "Train epoch 127: top1=0.7467699646949768%, top2=0.867389976978302%, top3=0.9146999716758728%, top4=0.9402899742126465%, top5=0.9555299878120422%, loss=0.052115996614024045, time=1377.325889825821s\n",
      "Train epoch 128: top1=0.7492499947547913%, top2=0.8701799511909485%, top3=0.9166100025177002%, top4=0.9415099620819092%, top5=0.9559800028800964%, loss=0.051603164469711485, time=1376.3935730457306s\n",
      "Train epoch 129: top1=0.7468699812889099%, top2=0.8673299551010132%, top3=0.9158899784088135%, top4=0.9408599734306335%, top5=0.9559299945831299%, loss=0.05198277370590717, time=1374.4596109390259s\n",
      "Train epoch 130: top1=0.7481799721717834%, top2=0.869439959526062%, top3=0.917449951171875%, top4=0.9425399899482727%, top5=0.9569799900054932%, loss=0.05152309130869806, time=1374.685986995697s\n",
      "Train epoch 131: top1=0.7497400045394897%, top2=0.870389997959137%, top3=0.9179299473762512%, top4=0.9421799778938293%, top5=0.9569699764251709%, loss=0.051279519200176, time=1378.3154768943787s\n",
      "Train epoch 132: top1=0.7499799728393555%, top2=0.8695399761199951%, top3=0.917419970035553%, top4=0.9421499967575073%, top5=0.9568599462509155%, loss=0.05131039436511695, time=1378.833815574646s\n",
      "Train epoch 133: top1=0.7494099736213684%, top2=0.8705899715423584%, top3=0.9181999564170837%, top4=0.9425699710845947%, top5=0.9576499462127686%, loss=0.05110446377556771, time=1377.751720905304s\n",
      "Train epoch 134: top1=0.7524099946022034%, top2=0.8733199834823608%, top3=0.9193099737167358%, top4=0.9433599710464478%, top5=0.9580999612808228%, loss=0.05065526436913759, time=1380.2436037063599s\n",
      "Train epoch 135: top1=0.7546899914741516%, top2=0.8741700053215027%, top3=0.9201299548149109%, top4=0.9437399506568909%, top5=0.9583500027656555%, loss=0.050198309454731645, time=1377.1858885288239s\n",
      "Train epoch 136: top1=0.756879985332489%, top2=0.8745099902153015%, top3=0.9208999872207642%, top4=0.9449599981307983%, top5=0.9596199989318848%, loss=0.049657171108350155, time=1377.6984343528748s\n",
      "Train epoch 137: top1=0.7582100033760071%, top2=0.8744699954986572%, top3=0.9201099872589111%, top4=0.9448099732398987%, top5=0.9602399468421936%, loss=0.04960219787165523, time=1376.6237177848816s\n",
      "Train epoch 138: top1=0.7564799785614014%, top2=0.8756499886512756%, top3=0.9221899509429932%, top4=0.945859968662262%, top5=0.9601500034332275%, loss=0.049608166637830436, time=1375.7279076576233s\n",
      "Train epoch 139: top1=0.7585799694061279%, top2=0.8766700029373169%, top3=0.9222599864006042%, top4=0.9452399611473083%, top5=0.9594699740409851%, loss=0.049559812651947144, time=1377.9773087501526s\n",
      "Train epoch 140: top1=0.7563799619674683%, top2=0.8752699494361877%, top3=0.9224199652671814%, top4=0.9456899762153625%, top5=0.9599499702453613%, loss=0.049599585200529546, time=1377.398029088974s\n",
      "Train epoch 141: top1=0.7596699595451355%, top2=0.8785399794578552%, top3=0.9243399500846863%, top4=0.9477399587631226%, top5=0.9614699482917786%, loss=0.04896264025181532, time=1377.7546410560608s\n",
      "Train epoch 142: top1=0.7627699971199036%, top2=0.8788699507713318%, top3=0.9250499606132507%, top4=0.948639988899231%, top5=0.9625299572944641%, loss=0.048460687313601376, time=1377.583293914795s\n",
      "Train epoch 143: top1=0.7602699995040894%, top2=0.8786199688911438%, top3=0.9236599802970886%, top4=0.9470299482345581%, top5=0.9615100026130676%, loss=0.04864947745703161, time=1377.465845823288s\n",
      "Train epoch 144: top1=0.7629599571228027%, top2=0.8797799944877625%, top3=0.9255499839782715%, top4=0.9486099481582642%, top5=0.9624300003051758%, loss=0.04814643905237317, time=1379.6726033687592s\n",
      "Train epoch 145: top1=0.7630999684333801%, top2=0.8810199499130249%, top3=0.9256399869918823%, top4=0.9479900002479553%, top5=0.9621099829673767%, loss=0.0480420551257208, time=1378.6346697807312s\n",
      "Train epoch 146: top1=0.762969970703125%, top2=0.8784099817276001%, top3=0.924239993095398%, top4=0.9486599564552307%, top5=0.9623599648475647%, loss=0.04834413052564487, time=1377.5802340507507s\n",
      "Train epoch 147: top1=0.7646899819374084%, top2=0.8815199732780457%, top3=0.9268699884414673%, top4=0.950249969959259%, top5=0.9636199474334717%, loss=0.04770413660738617, time=1376.959881067276s\n",
      "Train epoch 148: top1=0.7663699984550476%, top2=0.8826899528503418%, top3=0.9273200035095215%, top4=0.9511999487876892%, top5=0.9646399617195129%, loss=0.04732705555073917, time=1377.933931350708s\n",
      "Train epoch 149: top1=0.7655499577522278%, top2=0.8818099498748779%, top3=0.9265099763870239%, top4=0.949459969997406%, top5=0.963379979133606%, loss=0.04760343823445961, time=1379.8583834171295s\n",
      "Train epoch 150: top1=0.7680099606513977%, top2=0.8839899897575378%, top3=0.9274299740791321%, top4=0.951229989528656%, top5=0.9647299647331238%, loss=0.047038667978458105, time=1377.928771018982s\n",
      "Train epoch 151: top1=0.768339991569519%, top2=0.8855699896812439%, top3=0.9299699664115906%, top4=0.9518199563026428%, top5=0.9649699926376343%, loss=0.046824444936811926, time=1379.0515224933624s\n",
      "Train epoch 152: top1=0.7702999711036682%, top2=0.8851799964904785%, top3=0.9303699731826782%, top4=0.952049970626831%, top5=0.9652799963951111%, loss=0.04667140067022294, time=1378.3214557170868s\n",
      "Train epoch 153: top1=0.7701399922370911%, top2=0.8852399587631226%, top3=0.9293599724769592%, top4=0.9520300030708313%, top5=0.9650599956512451%, loss=0.04676287954479456, time=1376.2937219142914s\n",
      "Train epoch 154: top1=0.7741299867630005%, top2=0.8878499865531921%, top3=0.9319700002670288%, top4=0.9533900022506714%, top5=0.9664599895477295%, loss=0.04610254554081708, time=1377.6139690876007s\n",
      "Train epoch 155: top1=0.770859956741333%, top2=0.8864699602127075%, top3=0.9305399656295776%, top4=0.952709972858429%, top5=0.9660699963569641%, loss=0.046352632630243897, time=1377.7045168876648s\n",
      "Train epoch 156: top1=0.7724899649620056%, top2=0.8879099488258362%, top3=0.9312999844551086%, top4=0.9540299773216248%, top5=0.9661099910736084%, loss=0.045834446014985444, time=1375.4383807182312s\n",
      "Train epoch 157: top1=0.7748799920082092%, top2=0.8885200023651123%, top3=0.9323699474334717%, top4=0.9543899893760681%, top5=0.9670599699020386%, loss=0.04558473244534805, time=1377.7126202583313s\n",
      "Train epoch 158: top1=0.7734099626541138%, top2=0.8885999917984009%, top3=0.9326599836349487%, top4=0.9544999599456787%, top5=0.9671599864959717%, loss=0.04570648300562054, time=1376.9117069244385s\n",
      "Train epoch 159: top1=0.7752400040626526%, top2=0.8894099593162537%, top3=0.9330199956893921%, top4=0.9545599818229675%, top5=0.9679399728775024%, loss=0.045581704469248654, time=1376.9355101585388s\n",
      "Train epoch 160: top1=0.7761600017547607%, top2=0.8896999955177307%, top3=0.9328399896621704%, top4=0.9545499682426453%, top5=0.9673499464988708%, loss=0.04518800305392593, time=1376.2715048789978s\n",
      "Train epoch 161: top1=0.7740699648857117%, top2=0.8898599743843079%, top3=0.9324199557304382%, top4=0.9544599652290344%, top5=0.9669699668884277%, loss=0.045420658050533386, time=1377.8287584781647s\n",
      "Train epoch 162: top1=0.7766199707984924%, top2=0.8904100060462952%, top3=0.9338299632072449%, top4=0.9555999636650085%, top5=0.9676699638366699%, loss=0.04525922353565693, time=1378.154014825821s\n",
      "Train epoch 163: top1=0.7760799527168274%, top2=0.8906999826431274%, top3=0.9338399767875671%, top4=0.9552199840545654%, top5=0.9681399464607239%, loss=0.04498037204567343, time=1378.8491082191467s\n",
      "Train epoch 164: top1=0.776699960231781%, top2=0.8921599984169006%, top3=0.934909999370575%, top4=0.9567199945449829%, top5=0.9685499668121338%, loss=0.04488476594727486, time=1377.571715593338s\n",
      "Train epoch 165: top1=0.7788899540901184%, top2=0.8921599984169006%, top3=0.9350099563598633%, top4=0.9567599892616272%, top5=0.9690199494361877%, loss=0.04447361337754875, time=1378.5503571033478s\n",
      "Train epoch 166: top1=0.7798699736595154%, top2=0.8936899900436401%, top3=0.9361099600791931%, top4=0.9572199583053589%, top5=0.9691499471664429%, loss=0.044251490666754545, time=1379.0553166866302s\n",
      "Train epoch 167: top1=0.7812599539756775%, top2=0.8931399583816528%, top3=0.934689998626709%, top4=0.9555599689483643%, top5=0.9680999517440796%, loss=0.04426170337821357, time=1378.2554771900177s\n",
      "Train epoch 168: top1=0.7799800038337708%, top2=0.8928499817848206%, top3=0.9342899918556213%, top4=0.9558199644088745%, top5=0.9680899977684021%, loss=0.044441516831070185, time=1378.5432500839233s\n",
      "Train epoch 169: top1=0.7810699939727783%, top2=0.8942199945449829%, top3=0.9360299706459045%, top4=0.9571899771690369%, top5=0.9691499471664429%, loss=0.044071993224024775, time=1379.1738352775574s\n",
      "Train epoch 170: top1=0.7816500067710876%, top2=0.8942899703979492%, top3=0.9366599917411804%, top4=0.9575799703598022%, top5=0.9702699780464172%, loss=0.04392885355899111, time=1378.95063829422s\n",
      "Train epoch 171: top1=0.7840499877929688%, top2=0.8959299921989441%, top3=0.9378499984741211%, top4=0.9578499794006348%, top5=0.9700199961662292%, loss=0.04350479540582746, time=1376.1600546836853s\n",
      "Train epoch 172: top1=0.7816699743270874%, top2=0.8950999975204468%, top3=0.9364699721336365%, top4=0.9575199484825134%, top5=0.9695099592208862%, loss=0.04380800469037145, time=1377.7633452415466s\n",
      "Train epoch 173: top1=0.7839699983596802%, top2=0.8958699703216553%, top3=0.9385899901390076%, top4=0.9579899907112122%, top5=0.9703599810600281%, loss=0.04337301021892578, time=1376.6047048568726s\n",
      "Train epoch 174: top1=0.7823299765586853%, top2=0.8950499892234802%, top3=0.9364599585533142%, top4=0.9575799703598022%, top5=0.9701299667358398%, loss=0.043545365015529094, time=1377.2089099884033s\n",
      "Train epoch 175: top1=0.7840999960899353%, top2=0.8956499695777893%, top3=0.936989963054657%, top4=0.9578399658203125%, top5=0.9703699946403503%, loss=0.04359940756279975, time=1377.4666075706482s\n",
      "Train epoch 176: top1=0.7847999930381775%, top2=0.8972199559211731%, top3=0.9383800029754639%, top4=0.959089994430542%, top5=0.9706699848175049%, loss=0.04312221347693354, time=1378.1819250583649s\n",
      "Train epoch 177: top1=0.7860999703407288%, top2=0.8981899619102478%, top3=0.9387999773025513%, top4=0.9587799906730652%, top5=0.9709799885749817%, loss=0.04312918113724329, time=1380.0962479114532s\n",
      "Train epoch 178: top1=0.7862299680709839%, top2=0.8984999656677246%, top3=0.9380300045013428%, top4=0.9587099552154541%, top5=0.9705999493598938%, loss=0.04305792175023816, time=1379.3547940254211s\n",
      "Train epoch 179: top1=0.7868499755859375%, top2=0.8979899883270264%, top3=0.9394499659538269%, top4=0.9595299959182739%, top5=0.9710299968719482%, loss=0.04285884567856789, time=1379.2656879425049s\n",
      "Train epoch 180: top1=0.7865699529647827%, top2=0.8974499702453613%, top3=0.9387099742889404%, top4=0.9602099657058716%, top5=0.9719099998474121%, loss=0.04283157192500308, time=1381.0230793952942s\n",
      "Train epoch 181: top1=0.7895199656486511%, top2=0.8992899656295776%, top3=0.9402499794960022%, top4=0.959909975528717%, top5=0.9714499711990356%, loss=0.04234978000897914, time=1379.7218766212463s\n",
      "Train epoch 182: top1=0.7879199981689453%, top2=0.8985399603843689%, top3=0.9397199749946594%, top4=0.9597599506378174%, top5=0.9716599583625793%, loss=0.042442823534514756, time=1378.926638841629s\n",
      "Train epoch 183: top1=0.7902199625968933%, top2=0.9006199836730957%, top3=0.9407899975776672%, top4=0.9605699777603149%, top5=0.9716299772262573%, loss=0.04186159525576979, time=1378.905347585678s\n",
      "Train epoch 184: top1=0.789900004863739%, top2=0.9001699686050415%, top3=0.9406799674034119%, top4=0.9608399868011475%, top5=0.972089946269989%, loss=0.04221161843238398, time=1378.1447200775146s\n",
      "Train epoch 185: top1=0.7898799777030945%, top2=0.9009899497032166%, top3=0.9419699907302856%, top4=0.9619799852371216%, top5=0.9726899862289429%, loss=0.042037602548487485, time=1378.8114676475525s\n",
      "Train epoch 186: top1=0.7925699949264526%, top2=0.9031199812889099%, top3=0.942110002040863%, top4=0.9618699550628662%, top5=0.9734599590301514%, loss=0.0415120708331652, time=1377.7968475818634s\n",
      "Train epoch 187: top1=0.7907899618148804%, top2=0.9021799564361572%, top3=0.9422399997711182%, top4=0.9620599746704102%, top5=0.9732399582862854%, loss=0.041731027441285554, time=1377.8457698822021s\n",
      "Train epoch 188: top1=0.7910799980163574%, top2=0.901479959487915%, top3=0.941849946975708%, top4=0.9617499709129333%, top5=0.9731999635696411%, loss=0.04156366532091051, time=1377.0745840072632s\n",
      "Train epoch 189: top1=0.7915199995040894%, top2=0.9026299715042114%, top3=0.9419299960136414%, top4=0.9616999626159668%, top5=0.9727699756622314%, loss=0.04181520865380764, time=1377.5792546272278s\n",
      "Train epoch 190: top1=0.7936199903488159%, top2=0.9038899540901184%, top3=0.9427399635314941%, top4=0.9623299837112427%, top5=0.9729599952697754%, loss=0.041321692892983555, time=1378.7201611995697s\n",
      "Train epoch 191: top1=0.793969988822937%, top2=0.9033299684524536%, top3=0.9428499937057495%, top4=0.9624699950218201%, top5=0.9736999869346619%, loss=0.041314388371258975, time=1377.727341890335s\n",
      "Train epoch 192: top1=0.7918499708175659%, top2=0.9035199880599976%, top3=0.9434700012207031%, top4=0.9626599550247192%, top5=0.974109947681427%, loss=0.04140291722380556, time=1378.8752055168152s\n",
      "Train epoch 193: top1=0.7947899699211121%, top2=0.9037999510765076%, top3=0.9428799748420715%, top4=0.9625699520111084%, top5=0.973099946975708%, loss=0.041329033466130496, time=1377.10293841362s\n",
      "Train epoch 194: top1=0.7937699556350708%, top2=0.9040699601173401%, top3=0.9425399899482727%, top4=0.9620199799537659%, top5=0.9732199907302856%, loss=0.04122636570841074, time=1378.8569009304047s\n",
      "Train epoch 195: top1=0.7942900061607361%, top2=0.902209997177124%, top3=0.9433499574661255%, top4=0.9630999565124512%, top5=0.9749199748039246%, loss=0.04103367757467553, time=1377.207729101181s\n",
      "Train epoch 196: top1=0.7980899810791016%, top2=0.9049599766731262%, top3=0.9442799687385559%, top4=0.9632299542427063%, top5=0.9741699695587158%, loss=0.040575951898954805, time=1378.874885559082s\n",
      "Train epoch 197: top1=0.7971299886703491%, top2=0.9043899774551392%, top3=0.9436399936676025%, top4=0.9630699753761292%, top5=0.9739899635314941%, loss=0.04064204534789547, time=1376.8253962993622s\n",
      "Train epoch 198: top1=0.7956699728965759%, top2=0.9053099751472473%, top3=0.9445199966430664%, top4=0.9637999534606934%, top5=0.9748499989509583%, loss=0.04057336353028193, time=1376.114895582199s\n",
      "Train epoch 199: top1=0.7963999509811401%, top2=0.905299961566925%, top3=0.9436099529266357%, top4=0.9634499549865723%, top5=0.9745000004768372%, loss=0.04070537806818262, time=1377.5218741893768s\n",
      "Train epoch 200: top1=0.7988899946212769%, top2=0.9079999923706055%, top3=0.9466099739074707%, top4=0.9648199677467346%, top5=0.975629985332489%, loss=0.04015599517572671, time=1376.3266913890839s\n",
      "Train epoch 201: top1=0.7992199659347534%, top2=0.9067599773406982%, top3=0.9465199708938599%, top4=0.9643299579620361%, top5=0.9747799634933472%, loss=0.03997505565427244, time=1377.0371005535126s\n",
      "Train epoch 202: top1=0.7963399887084961%, top2=0.9075999855995178%, top3=0.9463899731636047%, top4=0.964959979057312%, top5=0.9758299589157104%, loss=0.040209803577428684, time=1379.7136299610138s\n",
      "Train epoch 203: top1=0.799869954586029%, top2=0.9066199660301208%, top3=0.9457899928092957%, top4=0.9646799564361572%, top5=0.9752599596977234%, loss=0.04001596978530288, time=1378.0701351165771s\n",
      "Train epoch 204: top1=0.8006799817085266%, top2=0.9067699909210205%, top3=0.9454599618911743%, top4=0.9644899964332581%, top5=0.9752699732780457%, loss=0.039716498285960404, time=1376.2062320709229s\n",
      "Train epoch 205: top1=0.8013699650764465%, top2=0.9070999622344971%, top3=0.946370005607605%, top4=0.9641199707984924%, top5=0.9749899506568909%, loss=0.040114396654628216, time=1378.4342682361603s\n",
      "Train epoch 206: top1=0.8024799823760986%, top2=0.9094299674034119%, top3=0.9472799897193909%, top4=0.9658599495887756%, top5=0.9761199951171875%, loss=0.039565552543010564, time=1378.8652927875519s\n",
      "Train epoch 207: top1=0.8017500042915344%, top2=0.9087199568748474%, top3=0.9467999935150146%, top4=0.966189980506897%, top5=0.9762899875640869%, loss=0.03966156323235482, time=1377.601458787918s\n",
      "Train epoch 208: top1=0.802079975605011%, top2=0.9094799757003784%, top3=0.9479199647903442%, top4=0.9657399654388428%, top5=0.9757899641990662%, loss=0.03945633112549782, time=1376.3637156486511s\n",
      "Train epoch 209: top1=0.8031599521636963%, top2=0.9093199968338013%, top3=0.9477599859237671%, top4=0.965999960899353%, top5=0.9771299958229065%, loss=0.039275078317634764, time=1377.0301558971405s\n",
      "Train epoch 210: top1=0.7999699711799622%, top2=0.9086299538612366%, top3=0.9465799927711487%, top4=0.9652299880981445%, top5=0.976099967956543%, loss=0.03961432973150164, time=1376.7251920700073s\n",
      "Train epoch 211: top1=0.8021199703216553%, top2=0.9089099764823914%, top3=0.947160005569458%, top4=0.9654399752616882%, top5=0.9762799739837646%, loss=0.039283152654841544, time=1378.874456167221s\n",
      "Train epoch 212: top1=0.8020399808883667%, top2=0.9083499908447266%, top3=0.9472399950027466%, top4=0.9652799963951111%, top5=0.9760899543762207%, loss=0.03937769090458751, time=1378.0340826511383s\n",
      "Train epoch 213: top1=0.8028599619865417%, top2=0.91007000207901%, top3=0.9472999572753906%, top4=0.9659799933433533%, top5=0.9762499928474426%, loss=0.039315418455619366, time=1378.8959515094757s\n",
      "Train epoch 214: top1=0.8035099506378174%, top2=0.9093700051307678%, top3=0.9472900032997131%, top4=0.9665599465370178%, top5=0.97666996717453%, loss=0.03922312086045742, time=1378.5755362510681s\n",
      "Train epoch 215: top1=0.8037999868392944%, top2=0.9108799695968628%, top3=0.9480399489402771%, top4=0.9655900001525879%, top5=0.9757599830627441%, loss=0.03893191751930863, time=1380.4847507476807s\n",
      "Train epoch 216: top1=0.8048799633979797%, top2=0.9113799929618835%, top3=0.9488399624824524%, top4=0.9670199751853943%, top5=0.9770699739456177%, loss=0.03884062263368629, time=1378.4128551483154s\n",
      "Train epoch 217: top1=0.8023799657821655%, top2=0.9106899499893188%, top3=0.9480099678039551%, top4=0.9665299654006958%, top5=0.9766299724578857%, loss=0.03922805813654326, time=1378.9722430706024s\n",
      "Train epoch 218: top1=0.8044899702072144%, top2=0.9109299778938293%, top3=0.9473699927330017%, top4=0.9658899903297424%, top5=0.9764599800109863%, loss=0.03887274241466075, time=1378.7046031951904s\n",
      "Train epoch 219: top1=0.8042399883270264%, top2=0.909280002117157%, top3=0.9473999738693237%, top4=0.9657299518585205%, top5=0.9762099981307983%, loss=0.039208873174730687, time=1377.9819114208221s\n",
      "Train epoch 220: top1=0.8069799542427063%, top2=0.9108099937438965%, top3=0.949459969997406%, top4=0.9681199789047241%, top5=0.9776600003242493%, loss=0.038556046853158624, time=1378.0591833591461s\n",
      "Train epoch 221: top1=0.8061699867248535%, top2=0.9116799831390381%, top3=0.948419988155365%, top4=0.9671300053596497%, top5=0.9772299528121948%, loss=0.03871084174724296, time=1379.0246031284332s\n",
      "Train epoch 222: top1=0.8060899972915649%, top2=0.9131199717521667%, top3=0.9501699805259705%, top4=0.9681699872016907%, top5=0.977929949760437%, loss=0.03828156245067715, time=1381.6822781562805s\n",
      "Train epoch 223: top1=0.8078299760818481%, top2=0.9129299521446228%, top3=0.9500699639320374%, top4=0.9675099849700928%, top5=0.9778800010681152%, loss=0.03829824470249936, time=1380.5581142902374s\n",
      "Train epoch 224: top1=0.8090699911117554%, top2=0.9131799936294556%, top3=0.9500299692153931%, top4=0.9675999879837036%, top5=0.9772999882698059%, loss=0.038033539252467455, time=1379.6400563716888s\n",
      "Train epoch 225: top1=0.8072800040245056%, top2=0.9125499725341797%, top3=0.9496199488639832%, top4=0.9675499796867371%, top5=0.9779199957847595%, loss=0.03824034759014845, time=1379.5204904079437s\n",
      "Train epoch 226: top1=0.8082299828529358%, top2=0.914359986782074%, top3=0.9510599970817566%, top4=0.9685899615287781%, top5=0.9783399701118469%, loss=0.037791679703202095, time=1380.3547070026398s\n",
      "Train epoch 227: top1=0.8091899752616882%, top2=0.9147799611091614%, top3=0.951229989528656%, top4=0.9687100052833557%, top5=0.978190004825592%, loss=0.037808866167608646, time=1378.1178724765778s\n",
      "Train epoch 228: top1=0.8103899955749512%, top2=0.914680004119873%, top3=0.9511299729347229%, top4=0.9683099985122681%, top5=0.9783299565315247%, loss=0.03791809423718601, time=1377.3992383480072s\n",
      "Train epoch 229: top1=0.8081600069999695%, top2=0.9151299595832825%, top3=0.9509999752044678%, top4=0.9686200022697449%, top5=0.9782399535179138%, loss=0.038087939118379724, time=1375.623351097107s\n",
      "Train epoch 230: top1=0.8091399669647217%, top2=0.9132699966430664%, top3=0.9500199556350708%, top4=0.9678899645805359%, top5=0.9784799814224243%, loss=0.03792980778245255, time=1377.5527992248535s\n",
      "Train epoch 231: top1=0.8115699887275696%, top2=0.9150599837303162%, top3=0.9511299729347229%, top4=0.9683399796485901%, top5=0.9778800010681152%, loss=0.037593264385750516, time=1378.1172552108765s\n",
      "Train epoch 232: top1=0.8107500076293945%, top2=0.9161099791526794%, top3=0.952269971370697%, top4=0.9691799879074097%, top5=0.9788900017738342%, loss=0.03748004132906906, time=1378.2700552940369s\n",
      "Train epoch 233: top1=0.8087899684906006%, top2=0.914359986782074%, top3=0.95100998878479%, top4=0.9678699970245361%, top5=0.9780399799346924%, loss=0.038063865487072614, time=1378.4818649291992s\n",
      "Train epoch 234: top1=0.8082099556922913%, top2=0.9127599596977234%, top3=0.9503600001335144%, top4=0.9678199887275696%, top5=0.9775799512863159%, loss=0.038240588128343224, time=1379.3022689819336s\n",
      "Train epoch 235: top1=0.8125699758529663%, top2=0.9157899618148804%, top3=0.9519400000572205%, top4=0.968970000743866%, top5=0.9787600040435791%, loss=0.037442548711262645, time=1379.5793390274048s\n",
      "Train epoch 236: top1=0.8097599744796753%, top2=0.9148799777030945%, top3=0.9508900046348572%, top4=0.9681800007820129%, top5=0.9777299761772156%, loss=0.03771558573259972, time=1378.9392642974854s\n",
      "Train epoch 237: top1=0.8104199767112732%, top2=0.915690004825592%, top3=0.9517599940299988%, top4=0.9693099856376648%, top5=0.979159951210022%, loss=0.03746483085239306, time=1377.7400465011597s\n",
      "Train epoch 238: top1=0.8134700059890747%, top2=0.9178499579429626%, top3=0.9522099494934082%, top4=0.9692399501800537%, top5=0.9795299768447876%, loss=0.037075761550050226, time=1378.0668094158173s\n",
      "Train epoch 239: top1=0.8119099736213684%, top2=0.9155799746513367%, top3=0.9518799781799316%, top4=0.9688599705696106%, top5=0.978469967842102%, loss=0.03733200720828027, time=1378.1245810985565s\n",
      "Train epoch 240: top1=0.8142799735069275%, top2=0.9168499708175659%, top3=0.9522799849510193%, top4=0.9694499969482422%, top5=0.9787499904632568%, loss=0.03700663822932169, time=1377.3059844970703s\n",
      "Train epoch 241: top1=0.8136499524116516%, top2=0.9173699617385864%, top3=0.9525799751281738%, top4=0.9697199463844299%, top5=0.9790999889373779%, loss=0.036950856411941346, time=1378.380200624466s\n",
      "Train epoch 242: top1=0.8138299584388733%, top2=0.9170099496841431%, top3=0.9534599781036377%, top4=0.9700799584388733%, top5=0.9791999459266663%, loss=0.03698408091409132, time=1377.416822195053s\n",
      "Train epoch 243: top1=0.8152099847793579%, top2=0.9180499911308289%, top3=0.9535099864006042%, top4=0.9703599810600281%, top5=0.9798199534416199%, loss=0.03676428874937818, time=1377.8046915531158s\n",
      "Train epoch 244: top1=0.8117499947547913%, top2=0.9160400032997131%, top3=0.9517499804496765%, top4=0.9688999652862549%, top5=0.9782999753952026%, loss=0.03711165044760332, time=1380.4281585216522s\n",
      "Train epoch 245: top1=0.8135799765586853%, top2=0.9170299768447876%, top3=0.952709972858429%, top4=0.9694199562072754%, top5=0.9786700010299683%, loss=0.037127417316734794, time=1378.7979106903076s\n",
      "Train epoch 246: top1=0.8138299584388733%, top2=0.917419970035553%, top3=0.9527199864387512%, top4=0.9695999622344971%, top5=0.9794099926948547%, loss=0.03683826244527474, time=1379.0487003326416s\n",
      "Train epoch 247: top1=0.8156599998474121%, top2=0.9163299798965454%, top3=0.9527599811553955%, top4=0.9693599939346313%, top5=0.9788599610328674%, loss=0.036760342453997584, time=1378.609866142273s\n",
      "Train epoch 248: top1=0.8134099841117859%, top2=0.9172799587249756%, top3=0.9535599946975708%, top4=0.9701399803161621%, top5=0.9793799519538879%, loss=0.03692605825811625, time=1379.061142206192s\n",
      "Train epoch 249: top1=0.8149499893188477%, top2=0.9171499609947205%, top3=0.9538399577140808%, top4=0.9704299569129944%, top5=0.9797199964523315%, loss=0.03673345546206459, time=1377.1747109889984s\n",
      "Train epoch 250: top1=0.815019965171814%, top2=0.9188399910926819%, top3=0.9541299939155579%, top4=0.9703699946403503%, top5=0.9797700047492981%, loss=0.036602894336478786, time=1378.8092358112335s\n",
      "Train epoch 251: top1=0.8154499530792236%, top2=0.9175799489021301%, top3=0.9535999894142151%, top4=0.9706799983978271%, top5=0.9805399775505066%, loss=0.03655435287662782, time=1379.8983414173126s\n",
      "Train epoch 252: top1=0.8156299591064453%, top2=0.9183299541473389%, top3=0.9535399675369263%, top4=0.9699699878692627%, top5=0.9790999889373779%, loss=0.036513587608747185, time=1378.5865008831024s\n",
      "Train epoch 253: top1=0.8162599802017212%, top2=0.9195999503135681%, top3=0.9548799991607666%, top4=0.9710299968719482%, top5=0.9797499775886536%, loss=0.03638154213115573, time=1380.5156588554382s\n",
      "Train epoch 254: top1=0.8173699975013733%, top2=0.9196400046348572%, top3=0.9536999464035034%, top4=0.9706199765205383%, top5=0.979699969291687%, loss=0.036325355052221564, time=1380.3537697792053s\n",
      "Train epoch 255: top1=0.8151299953460693%, top2=0.9173099994659424%, top3=0.9534399509429932%, top4=0.9704499840736389%, top5=0.9800999760627747%, loss=0.036644262958318, time=1379.5768642425537s\n",
      "Train epoch 256: top1=0.8166399598121643%, top2=0.9190099835395813%, top3=0.9541999697685242%, top4=0.9704599976539612%, top5=0.9802199602127075%, loss=0.03645752964451909, time=1378.544438123703s\n",
      "Train epoch 257: top1=0.8176199793815613%, top2=0.919029951095581%, top3=0.9542499780654907%, top4=0.9709099531173706%, top5=0.9802799820899963%, loss=0.03626500504044816, time=1380.016173839569s\n",
      "Train epoch 258: top1=0.8176699876785278%, top2=0.9207299947738647%, top3=0.9549399614334106%, top4=0.9714300036430359%, top5=0.9805499911308289%, loss=0.03626974254220724, time=1380.1693832874298s\n",
      "Train epoch 259: top1=0.8170799612998962%, top2=0.9210799932479858%, top3=0.9556099772453308%, top4=0.971780002117157%, top5=0.9808200001716614%, loss=0.035940058700013905, time=1378.344138622284s\n",
      "Train epoch 260: top1=0.8177499771118164%, top2=0.9195999503135681%, top3=0.95346999168396%, top4=0.9706199765205383%, top5=0.9800599813461304%, loss=0.03614377734855749, time=1379.1823556423187s\n",
      "Train epoch 261: top1=0.8184899687767029%, top2=0.9203899502754211%, top3=0.9547799825668335%, top4=0.9716299772262573%, top5=0.9807199835777283%, loss=0.03601731868047267, time=1377.9063084125519s\n",
      "Train epoch 262: top1=0.8153899908065796%, top2=0.9186199903488159%, top3=0.954319953918457%, top4=0.9708399772644043%, top5=0.9799999594688416%, loss=0.03637789481844753, time=1376.9742739200592s\n",
      "Train epoch 263: top1=0.8209699988365173%, top2=0.9210000038146973%, top3=0.9558299779891968%, top4=0.971809983253479%, top5=0.9807999730110168%, loss=0.03561988606415689, time=1377.403172492981s\n",
      "Train epoch 264: top1=0.8208099603652954%, top2=0.922029972076416%, top3=0.9565500020980835%, top4=0.9725499749183655%, top5=0.9811899662017822%, loss=0.035610689131049436, time=1377.5134208202362s\n",
      "Train epoch 265: top1=0.8195899724960327%, top2=0.9207499623298645%, top3=0.9562399983406067%, top4=0.972089946269989%, top5=0.9814199805259705%, loss=0.03549786801192909, time=1379.7355208396912s\n",
      "Train epoch 266: top1=0.8214399814605713%, top2=0.9208799600601196%, top3=0.9555899500846863%, top4=0.9718299508094788%, top5=0.9806999564170837%, loss=0.03551232003545388, time=1377.2842483520508s\n",
      "Train epoch 267: top1=0.8203399777412415%, top2=0.9209599494934082%, top3=0.955489993095398%, top4=0.9718599915504456%, top5=0.9815099835395813%, loss=0.035529101324435326, time=1377.826369047165s\n",
      "Train epoch 268: top1=0.820169985294342%, top2=0.9225099682807922%, top3=0.9553200006484985%, top4=0.9717699885368347%, top5=0.9810099601745605%, loss=0.035527591003458946, time=1379.9855136871338s\n",
      "Train epoch 269: top1=0.8229799866676331%, top2=0.9233299493789673%, top3=0.9569900035858154%, top4=0.973289966583252%, top5=0.9817999601364136%, loss=0.035003445472083984, time=1379.556875705719s\n",
      "Train epoch 270: top1=0.820930004119873%, top2=0.920989990234375%, top3=0.9556199908256531%, top4=0.9716500043869019%, top5=0.9808599948883057%, loss=0.035379482744243, time=1378.255686044693s\n",
      "Train epoch 271: top1=0.8209699988365173%, top2=0.9232199788093567%, top3=0.956779956817627%, top4=0.97257000207901%, top5=0.9813099503517151%, loss=0.03507408489689231, time=1378.5122804641724s\n",
      "Train epoch 272: top1=0.8217499852180481%, top2=0.9231599569320679%, top3=0.9573099613189697%, top4=0.9726600050926208%, top5=0.9814499616622925%, loss=0.03533024132711813, time=1379.8943395614624s\n",
      "Train epoch 273: top1=0.8225499987602234%, top2=0.9225099682807922%, top3=0.9559999704360962%, top4=0.9726399779319763%, top5=0.9815699458122253%, loss=0.03504491957099177, time=1380.2709438800812s\n",
      "Train epoch 274: top1=0.8218599557876587%, top2=0.921999990940094%, top3=0.9561599493026733%, top4=0.972089946269989%, top5=0.9810699820518494%, loss=0.03522826652109623, time=1380.5352127552032s\n",
      "Train epoch 275: top1=0.8207599520683289%, top2=0.9212799668312073%, top3=0.9555299878120422%, top4=0.9723899960517883%, top5=0.9816499948501587%, loss=0.03546474258184433, time=1380.223103761673s\n",
      "Train epoch 276: top1=0.821590006351471%, top2=0.9224399924278259%, top3=0.9563599824905396%, top4=0.9720099568367004%, top5=0.9810199737548828%, loss=0.035368015851527455, time=1378.619302034378s\n",
      "Train epoch 277: top1=0.821679949760437%, top2=0.9223299622535706%, top3=0.9573099613189697%, top4=0.9731799960136414%, top5=0.981499969959259%, loss=0.03532253966702148, time=1379.6835505962372s\n",
      "Train epoch 278: top1=0.8232100009918213%, top2=0.9237099885940552%, top3=0.9565199613571167%, top4=0.9725499749183655%, top5=0.9811300039291382%, loss=0.03477984555294737, time=1379.0326852798462s\n",
      "Train epoch 279: top1=0.8219299912452698%, top2=0.9212999939918518%, top3=0.9556599855422974%, top4=0.971780002117157%, top5=0.9809699654579163%, loss=0.03529356353713199, time=1378.5066652297974s\n",
      "Train epoch 280: top1=0.8209599852561951%, top2=0.922469973564148%, top3=0.9564899802207947%, top4=0.9724499583244324%, top5=0.9814899563789368%, loss=0.03546915837221779, time=1381.4461560249329s\n",
      "Train epoch 281: top1=0.8239499926567078%, top2=0.9227799773216248%, top3=0.9564499855041504%, top4=0.9720799922943115%, top5=0.9809399843215942%, loss=0.035081487852716815, time=1378.8146736621857s\n",
      "Train epoch 282: top1=0.8222900032997131%, top2=0.9230499863624573%, top3=0.9565199613571167%, top4=0.9729399681091309%, top5=0.9819299578666687%, loss=0.03493347257923335, time=1377.5972082614899s\n",
      "Train epoch 283: top1=0.823419988155365%, top2=0.9239799976348877%, top3=0.9571399688720703%, top4=0.9726799726486206%, top5=0.9815899729728699%, loss=0.03503089441107586, time=1378.8821170330048s\n",
      "Train epoch 284: top1=0.8226799964904785%, top2=0.9218899607658386%, top3=0.9565500020980835%, top4=0.972279965877533%, top5=0.9812899827957153%, loss=0.03515553404351696, time=1376.928645849228s\n",
      "Train epoch 285: top1=0.8258399963378906%, top2=0.9241899847984314%, top3=0.95756995677948%, top4=0.9726099967956543%, top5=0.9815099835395813%, loss=0.034610229133348915, time=1379.539397239685s\n",
      "Train epoch 286: top1=0.8258199691772461%, top2=0.9252499938011169%, top3=0.9572599530220032%, top4=0.9734599590301514%, top5=0.9821799993515015%, loss=0.03436398656978272, time=1379.6176273822784s\n",
      "Train epoch 287: top1=0.8236500024795532%, top2=0.9236799478530884%, top3=0.9576199650764465%, top4=0.9735099673271179%, top5=0.9818699955940247%, loss=0.03476496366285719, time=1377.9123666286469s\n",
      "Train epoch 288: top1=0.8277699947357178%, top2=0.9252099990844727%, top3=0.957889974117279%, top4=0.9734099507331848%, top5=0.9819599986076355%, loss=0.0342918100945279, time=1377.7834041118622s\n",
      "Train epoch 289: top1=0.8230299949645996%, top2=0.9243199825286865%, top3=0.9577999711036682%, top4=0.9732099771499634%, top5=0.9815599918365479%, loss=0.03474125916231889, time=1378.6539220809937s\n",
      "Train epoch 290: top1=0.826449990272522%, top2=0.9247300028800964%, top3=0.9575099945068359%, top4=0.9736599922180176%, top5=0.9817599654197693%, loss=0.03452937496284023, time=1377.8053154945374s\n",
      "Train epoch 291: top1=0.8223599791526794%, top2=0.9232099652290344%, top3=0.9567199945449829%, top4=0.9722399711608887%, top5=0.9815099835395813%, loss=0.035140867822431025, time=1379.0640232563019s\n",
      "Train epoch 292: top1=0.826449990272522%, top2=0.9252199530601501%, top3=0.9584399461746216%, top4=0.9740699529647827%, top5=0.9822399616241455%, loss=0.034383340203771366, time=1379.9026997089386s\n",
      "Train epoch 293: top1=0.8246699571609497%, top2=0.9238100051879883%, top3=0.9576199650764465%, top4=0.9734599590301514%, top5=0.9823899865150452%, loss=0.03469126763539389, time=1380.2669048309326s\n",
      "Train epoch 294: top1=0.8259999752044678%, top2=0.9259999990463257%, top3=0.9583099484443665%, top4=0.9733799695968628%, top5=0.9820099472999573%, loss=0.03435210068272427, time=1380.0102469921112s\n",
      "Train epoch 295: top1=0.825980007648468%, top2=0.9256799817085266%, top3=0.9577699899673462%, top4=0.9734299778938293%, top5=0.9816399812698364%, loss=0.03455048714786768, time=1378.1451983451843s\n",
      "Train epoch 296: top1=0.8261399865150452%, top2=0.9257899522781372%, top3=0.9596199989318848%, top4=0.9747499823570251%, top5=0.9830399751663208%, loss=0.034239171264767644, time=1378.6416425704956s\n",
      "Train epoch 297: top1=0.8264299631118774%, top2=0.9254699945449829%, top3=0.9582299590110779%, top4=0.9739199876785278%, top5=0.9822499752044678%, loss=0.03441606557383202, time=1386.2283327579498s\n",
      "Train epoch 298: top1=0.8251499533653259%, top2=0.9241699576377869%, top3=0.9581599831581116%, top4=0.9734899997711182%, top5=0.9822199940681458%, loss=0.034492614047024396, time=1387.3952898979187s\n",
      "Train epoch 299: top1=0.8261500000953674%, top2=0.9239699840545654%, top3=0.9563199877738953%, top4=0.9727699756622314%, top5=0.9813399910926819%, loss=0.03466441605389118, time=1769.3546013832092s\n",
      "Train epoch 300: top1=0.8279100060462952%, top2=0.9265799522399902%, top3=0.9587799906730652%, top4=0.973859965801239%, top5=0.9825999736785889%, loss=0.03395970489777625, time=1449.8433210849762s\n",
      "Train epoch 301: top1=0.8261199593544006%, top2=0.9248299598693848%, top3=0.9587599635124207%, top4=0.973609983921051%, top5=0.9815899729728699%, loss=0.03448928931504488, time=1430.0622248649597s\n",
      "Train epoch 302: top1=0.827489972114563%, top2=0.925089955329895%, top3=0.9593199491500854%, top4=0.974299967288971%, top5=0.9824000000953674%, loss=0.0342573656850867, time=1464.6791286468506s\n",
      "Train epoch 303: top1=0.8279799818992615%, top2=0.9256199598312378%, top3=0.9594799876213074%, top4=0.9747399687767029%, top5=0.982979953289032%, loss=0.03400465854831971, time=1401.8815484046936s\n",
      "Train epoch 304: top1=0.8261399865150452%, top2=0.9258099794387817%, top3=0.9595499634742737%, top4=0.974649965763092%, top5=0.9833799600601196%, loss=0.034241192374015225, time=1377.143069267273s\n",
      "Train epoch 305: top1=0.8273499608039856%, top2=0.926069974899292%, top3=0.9598499536514282%, top4=0.9751299619674683%, top5=0.9832299947738647%, loss=0.03396586643326096, time=1390.1117129325867s\n",
      "Train epoch 306: top1=0.8271200060844421%, top2=0.9251999855041504%, top3=0.9590299725532532%, top4=0.9741599559783936%, top5=0.9828599691390991%, loss=0.034117355887535956, time=1410.4338898658752s\n",
      "Train epoch 307: top1=0.8270399570465088%, top2=0.925599992275238%, top3=0.9581699967384338%, top4=0.9736999869346619%, top5=0.9823799729347229%, loss=0.03418656760151498, time=1406.0973427295685s\n",
      "Train epoch 308: top1=0.8295699954032898%, top2=0.9272899627685547%, top3=0.959879994392395%, top4=0.9746399521827698%, top5=0.9824900031089783%, loss=0.03373481301932596, time=1421.3518459796906s\n",
      "Train epoch 309: top1=0.828249990940094%, top2=0.9260099530220032%, top3=0.9590399861335754%, top4=0.9741999506950378%, top5=0.9827699661254883%, loss=0.03382895747265779, time=1434.3837532997131s\n",
      "Train epoch 310: top1=0.8275899887084961%, top2=0.9256999492645264%, top3=0.959309995174408%, top4=0.9749299883842468%, top5=0.9833999872207642%, loss=0.033908948540734125, time=1377.513000011444s\n",
      "Train epoch 311: top1=0.8293399810791016%, top2=0.9268099665641785%, top3=0.9594900012016296%, top4=0.9746899604797363%, top5=0.9830699563026428%, loss=0.03371345802692696, time=1377.9499673843384s\n",
      "Train epoch 312: top1=0.826509952545166%, top2=0.9256199598312378%, top3=0.958549976348877%, top4=0.9741999506950378%, top5=0.9825699925422668%, loss=0.0340787159857899, time=1377.5627319812775s\n",
      "Train epoch 313: top1=0.8289099931716919%, top2=0.9265499711036682%, top3=0.9592499732971191%, top4=0.9747200012207031%, top5=0.9826599955558777%, loss=0.03375101941196248, time=1376.6158068180084s\n",
      "Train epoch 314: top1=0.8276599645614624%, top2=0.9274999499320984%, top3=0.960599958896637%, top4=0.9752699732780457%, top5=0.9831699728965759%, loss=0.03385656435342506, time=1376.4793901443481s\n",
      "Train epoch 315: top1=0.8290599584579468%, top2=0.9262799620628357%, top3=0.9590299725532532%, top4=0.9747999906539917%, top5=0.9832800030708313%, loss=0.03382287067871541, time=1376.2921409606934s\n",
      "Train epoch 316: top1=0.8295699954032898%, top2=0.9257199764251709%, top3=0.958869993686676%, top4=0.9746899604797363%, top5=0.9832199811935425%, loss=0.033833489338103685, time=1375.7028987407684s\n",
      "Train epoch 317: top1=0.8288300037384033%, top2=0.926539957523346%, top3=0.9590499997138977%, top4=0.9742899537086487%, top5=0.9828799962997437%, loss=0.033841052331142124, time=1376.581074476242s\n",
      "Train epoch 318: top1=0.8314599990844727%, top2=0.9281799793243408%, top3=0.9601699709892273%, top4=0.9757699966430664%, top5=0.9837799668312073%, loss=0.03325479950388893, time=1374.1572201251984s\n",
      "Train epoch 319: top1=0.8298799991607666%, top2=0.9276599884033203%, top3=0.9601099491119385%, top4=0.9748199582099915%, top5=0.9832800030708313%, loss=0.03358355252440087, time=1375.8407413959503s\n",
      "Train epoch 320: top1=0.8303399682044983%, top2=0.9271299839019775%, top3=0.9601899981498718%, top4=0.975089967250824%, top5=0.9830199480056763%, loss=0.033485775693831966, time=1377.2344064712524s\n",
      "Train epoch 321: top1=0.8300999999046326%, top2=0.9279399514198303%, top3=0.9601699709892273%, top4=0.9750499725341797%, top5=0.9829599857330322%, loss=0.03357677805399522, time=1376.0841691493988s\n",
      "Train epoch 322: top1=0.8299199938774109%, top2=0.9294700026512146%, top3=0.9608299732208252%, top4=0.9757699966430664%, top5=0.9837200045585632%, loss=0.03351857441574335, time=1375.7113258838654s\n",
      "Train epoch 323: top1=0.8324699997901917%, top2=0.9288699626922607%, top3=0.9610999822616577%, top4=0.9754599928855896%, top5=0.9835999608039856%, loss=0.03324409161212388, time=1377.0943999290466s\n",
      "Train epoch 324: top1=0.8294299840927124%, top2=0.9272699952125549%, top3=0.9599899649620056%, top4=0.9746799468994141%, top5=0.9827999472618103%, loss=0.033718583980984984, time=1376.8928351402283s\n",
      "Train epoch 325: top1=0.8313300013542175%, top2=0.9273999929428101%, top3=0.9602299928665161%, top4=0.9754699468612671%, top5=0.9836300015449524%, loss=0.03324725061886013, time=1376.5248937606812s\n",
      "Train epoch 326: top1=0.8321899771690369%, top2=0.9293699860572815%, top3=0.9608500003814697%, top4=0.9748599529266357%, top5=0.9836099743843079%, loss=0.0332438743619062, time=1375.814816236496s\n",
      "Train epoch 327: top1=0.8316400051116943%, top2=0.9281499981880188%, top3=0.9597599506378174%, top4=0.9753099679946899%, top5=0.983489990234375%, loss=0.03332229500104208, time=1375.6486871242523s\n",
      "Train epoch 328: top1=0.8299599885940552%, top2=0.9266299605369568%, top3=0.9601099491119385%, top4=0.9748499989509583%, top5=0.9833899736404419%, loss=0.033657567029036585, time=1377.2460606098175s\n",
      "Train epoch 329: top1=0.8314899802207947%, top2=0.9291200041770935%, top3=0.9619199633598328%, top4=0.9761499762535095%, top5=0.9839999675750732%, loss=0.033100002016667275, time=1376.1827154159546s\n",
      "Train epoch 330: top1=0.8330099582672119%, top2=0.9289699792861938%, top3=0.9606199860572815%, top4=0.9759699702262878%, top5=0.9836999773979187%, loss=0.03291437192007899, time=1376.66641330719s\n",
      "Train epoch 331: top1=0.832789957523346%, top2=0.9302999973297119%, top3=0.9618499875068665%, top4=0.976419985294342%, top5=0.9843699932098389%, loss=0.032927844410911206, time=1375.9914336204529s\n",
      "Train epoch 332: top1=0.8331300020217896%, top2=0.9285899996757507%, top3=0.9606799483299255%, top4=0.9757699966430664%, top5=0.9837599992752075%, loss=0.03296663584182039, time=1377.4888372421265s\n",
      "Train epoch 333: top1=0.8313199877738953%, top2=0.9288599491119385%, top3=0.9612900018692017%, top4=0.9757399559020996%, top5=0.9838999509811401%, loss=0.033217611535042525, time=1376.209419965744s\n",
      "Train epoch 334: top1=0.831279993057251%, top2=0.9289599657058716%, top3=0.9614899754524231%, top4=0.975380003452301%, top5=0.9832599759101868%, loss=0.033371453345254994, time=1376.875994682312s\n",
      "Train epoch 335: top1=0.8294599652290344%, top2=0.9282199740409851%, top3=0.9601899981498718%, top4=0.9757999777793884%, top5=0.9834699630737305%, loss=0.03351304327860474, time=1377.2130286693573s\n",
      "Train epoch 336: top1=0.8322100043296814%, top2=0.930109977722168%, top3=0.9615499973297119%, top4=0.9762899875640869%, top5=0.9839299917221069%, loss=0.03284198552780319, time=1377.232656955719s\n",
      "Train epoch 337: top1=0.8320199847221375%, top2=0.9288399815559387%, top3=0.961169958114624%, top4=0.9755399823188782%, top5=0.9844200015068054%, loss=0.03301091167680919, time=1377.3316321372986s\n",
      "Train epoch 338: top1=0.8295799493789673%, top2=0.9284899830818176%, top3=0.9606899619102478%, top4=0.9757699966430664%, top5=0.9836300015449524%, loss=0.03346056011081673, time=1377.3050003051758s\n",
      "Train epoch 339: top1=0.8312599658966064%, top2=0.9271999597549438%, top3=0.9602800011634827%, top4=0.9747799634933472%, top5=0.9829899668693542%, loss=0.03347010399837047, time=1379.3072187900543s\n",
      "Train epoch 340: top1=0.8306499719619751%, top2=0.9277699589729309%, top3=0.9599300026893616%, top4=0.9752699732780457%, top5=0.9835000038146973%, loss=0.03347303099591285, time=1378.984702348709s\n",
      "Train epoch 341: top1=0.8309299945831299%, top2=0.9273899793624878%, top3=0.9601399898529053%, top4=0.9755199551582336%, top5=0.9833999872207642%, loss=0.03328380181645974, time=1375.2385318279266s\n",
      "Train epoch 342: top1=0.8305599689483643%, top2=0.9285999536514282%, top3=0.9604299664497375%, top4=0.9751499891281128%, top5=0.9832800030708313%, loss=0.03347949776311405, time=1376.801729440689s\n",
      "Train epoch 343: top1=0.832889974117279%, top2=0.9302899837493896%, top3=0.9615399837493896%, top4=0.9758599996566772%, top5=0.9839299917221069%, loss=0.03287424677683972, time=1378.021229982376s\n",
      "Train epoch 344: top1=0.83256995677948%, top2=0.9297099709510803%, top3=0.961359977722168%, top4=0.9754399657249451%, top5=0.9836699962615967%, loss=0.03318302742209169, time=1377.9274003505707s\n",
      "Train epoch 345: top1=0.8337399959564209%, top2=0.9293099641799927%, top3=0.9607599973678589%, top4=0.9757300019264221%, top5=0.9836999773979187%, loss=0.0329530183459539, time=1378.4010541439056s\n",
      "Train epoch 346: top1=0.8332599997520447%, top2=0.9294899702072144%, top3=0.9609799981117249%, top4=0.9761999845504761%, top5=0.9839699864387512%, loss=0.03302252439721488, time=1377.4734919071198s\n",
      "Train epoch 347: top1=0.833329975605011%, top2=0.9294899702072144%, top3=0.9617899656295776%, top4=0.976099967956543%, top5=0.9840999841690063%, loss=0.03278828112631105, time=1377.4108228683472s\n",
      "Train epoch 348: top1=0.8323299884796143%, top2=0.9283999800682068%, top3=0.9602599740028381%, top4=0.9757399559020996%, top5=0.9838999509811401%, loss=0.032982860533390196, time=1376.6542246341705s\n",
      "Train epoch 349: top1=0.8336699604988098%, top2=0.9296900033950806%, top3=0.9613099694252014%, top4=0.9756399989128113%, top5=0.983549952507019%, loss=0.032938745618704704, time=1376.3416786193848s\n",
      "Train epoch 350: top1=0.8344799876213074%, top2=0.9305599927902222%, top3=0.960919976234436%, top4=0.9763000011444092%, top5=0.9840099811553955%, loss=0.032747412928333504, time=1374.72403216362s\n",
      "Train epoch 351: top1=0.8341799974441528%, top2=0.9306199550628662%, top3=0.9627299904823303%, top4=0.9769699573516846%, top5=0.984559953212738%, loss=0.032654813032578674, time=1376.8776466846466s\n",
      "Train epoch 352: top1=0.8318099975585938%, top2=0.9283899664878845%, top3=0.9609299898147583%, top4=0.9756499528884888%, top5=0.9835399985313416%, loss=0.03314663589367643, time=1377.9655892848969s\n",
      "Train epoch 353: top1=0.8329499959945679%, top2=0.9300699830055237%, top3=0.9618399739265442%, top4=0.976099967956543%, top5=0.9836899638175964%, loss=0.03304690288359299, time=1377.0923511981964s\n",
      "Train epoch 354: top1=0.8367300033569336%, top2=0.9316299557685852%, top3=0.9619199633598328%, top4=0.9762599468231201%, top5=0.9837799668312073%, loss=0.0323161493284069, time=1376.7672309875488s\n",
      "Train epoch 355: top1=0.8318299651145935%, top2=0.9294099807739258%, top3=0.9611600041389465%, top4=0.9758999943733215%, top5=0.9841699600219727%, loss=0.03317272624837234, time=1377.7919375896454s\n",
      "Train epoch 356: top1=0.8339099884033203%, top2=0.9301799535751343%, top3=0.9614799618721008%, top4=0.9757499694824219%, top5=0.983199954032898%, loss=0.03292396332785487, time=1376.3305170536041s\n",
      "Train epoch 357: top1=0.8362799882888794%, top2=0.9313199520111084%, top3=0.9622899889945984%, top4=0.9767400026321411%, top5=0.9841399788856506%, loss=0.0324285515781492, time=1377.0169892311096s\n",
      "Train epoch 358: top1=0.8333699703216553%, top2=0.9311899542808533%, top3=0.9626099467277527%, top4=0.9763299822807312%, top5=0.9836699962615967%, loss=0.03283610335410573, time=1376.0845851898193s\n",
      "Train epoch 359: top1=0.83433997631073%, top2=0.92985999584198%, top3=0.9611299633979797%, top4=0.976349949836731%, top5=0.9836699962615967%, loss=0.032716545481979845, time=1376.2096738815308s\n",
      "Train epoch 360: top1=0.8369999527931213%, top2=0.9308599829673767%, top3=0.9626500010490417%, top4=0.9768099784851074%, top5=0.9846699833869934%, loss=0.03223793437731452, time=1378.4396703243256s\n",
      "Train epoch 361: top1=0.8356800079345703%, top2=0.9307699799537659%, top3=0.9620199799537659%, top4=0.9762599468231201%, top5=0.9839199781417847%, loss=0.03238852891068906, time=1376.3025801181793s\n",
      "Train epoch 362: top1=0.8349699974060059%, top2=0.9305699467658997%, top3=0.9619399905204773%, top4=0.9760599732398987%, top5=0.9843299984931946%, loss=0.032615891719982026, time=1376.1334507465363s\n",
      "Train epoch 363: top1=0.8351899981498718%, top2=0.9306599497795105%, top3=0.9624999761581421%, top4=0.9765599966049194%, top5=0.9844499826431274%, loss=0.032430258216764776, time=1375.7989048957825s\n",
      "Train epoch 364: top1=0.8346899747848511%, top2=0.9307699799537659%, top3=0.9615799784660339%, top4=0.9756799936294556%, top5=0.9837599992752075%, loss=0.03265105047990568, time=1376.920934677124s\n",
      "Train epoch 365: top1=0.8356999754905701%, top2=0.9311099648475647%, top3=0.9621700048446655%, top4=0.9765399694442749%, top5=0.9842499494552612%, loss=0.03251034915626049, time=1375.2370862960815s\n",
      "Train epoch 366: top1=0.8314200043678284%, top2=0.9290799498558044%, top3=0.9609299898147583%, top4=0.9757999777793884%, top5=0.9840099811553955%, loss=0.03298758084047586, time=1375.3685030937195s\n",
      "Train epoch 367: top1=0.8339599967002869%, top2=0.9310099482536316%, top3=0.9624300003051758%, top4=0.9768799543380737%, top5=0.9847099781036377%, loss=0.0325164615504723, time=1378.9946472644806s\n",
      "Train epoch 368: top1=0.8329499959945679%, top2=0.928879976272583%, top3=0.9612599611282349%, top4=0.9751799702644348%, top5=0.9835599660873413%, loss=0.03307150776742958, time=1375.8479421138763s\n",
      "Train epoch 369: top1=0.8338299989700317%, top2=0.9300400018692017%, top3=0.9613800048828125%, top4=0.9760499596595764%, top5=0.9839699864387512%, loss=0.03302871029415168, time=1378.6050465106964s\n",
      "Train epoch 370: top1=0.8366400003433228%, top2=0.9305799603462219%, top3=0.962179958820343%, top4=0.9764799475669861%, top5=0.983959972858429%, loss=0.032296711690295486, time=1377.9261207580566s\n",
      "Train epoch 371: top1=0.8343499898910522%, top2=0.9299699664115906%, top3=0.9612799882888794%, top4=0.9768700003623962%, top5=0.9846400022506714%, loss=0.03265567377170548, time=1378.513061761856s\n",
      "Train epoch 372: top1=0.8372299671173096%, top2=0.9310899972915649%, top3=0.9627299904823303%, top4=0.9775899648666382%, top5=0.9847399592399597%, loss=0.03225297771239653, time=1377.672040462494s\n",
      "Train epoch 373: top1=0.8362099528312683%, top2=0.9315499663352966%, top3=0.9629600048065186%, top4=0.9770099520683289%, top5=0.9844499826431274%, loss=0.032279048625156286, time=1378.6910238265991s\n",
      "Train epoch 374: top1=0.8330900073051453%, top2=0.930079996585846%, top3=0.9614699482917786%, top4=0.9758699536323547%, top5=0.9833299517631531%, loss=0.03305515756068751, time=1376.7714836597443s\n",
      "Train epoch 375: top1=0.8362599611282349%, top2=0.9314000010490417%, top3=0.9620699882507324%, top4=0.9766299724578857%, top5=0.9839199781417847%, loss=0.032317002373831345, time=1376.230060338974s\n",
      "Train epoch 376: top1=0.8354699611663818%, top2=0.929919958114624%, top3=0.9620299935340881%, top4=0.976639986038208%, top5=0.9845399856567383%, loss=0.032657199799232185, time=1375.7859075069427s\n",
      "Train epoch 377: top1=0.8329599499702454%, top2=0.9310500025749207%, top3=0.9628399610519409%, top4=0.9769399762153625%, top5=0.9843499660491943%, loss=0.03274228719713167, time=1377.05060172081s\n",
      "Train epoch 378: top1=0.8349599838256836%, top2=0.9312599897384644%, top3=0.9625099897384644%, top4=0.9764299988746643%, top5=0.9842099547386169%, loss=0.03246002579170279, time=1376.3289670944214s\n",
      "Train epoch 379: top1=0.8323299884796143%, top2=0.9300299882888794%, top3=0.9622899889945984%, top4=0.976699948310852%, top5=0.9846599698066711%, loss=0.032713082460705194, time=1375.7635021209717s\n",
      "Train epoch 380: top1=0.8393699526786804%, top2=0.9324699640274048%, top3=0.963379979133606%, top4=0.9777899980545044%, top5=0.9852699637413025%, loss=0.03179479761254042, time=1376.6791017055511s\n",
      "Train epoch 381: top1=0.8374399542808533%, top2=0.9330499768257141%, top3=0.9640399813652039%, top4=0.9779599905014038%, top5=0.9854499697685242%, loss=0.03178914344828576, time=1376.1797235012054s\n",
      "Train epoch 382: top1=0.8376799821853638%, top2=0.9329299926757812%, top3=0.9630199670791626%, top4=0.9767899513244629%, top5=0.9842900037765503%, loss=0.03188793519876897, time=1376.105488538742s\n",
      "Train epoch 383: top1=0.8378700017929077%, top2=0.9317799806594849%, top3=0.9630099534988403%, top4=0.9767899513244629%, top5=0.9848499894142151%, loss=0.032079657359030095, time=1376.9019422531128s\n",
      "Train epoch 384: top1=0.8373299837112427%, top2=0.9314099550247192%, top3=0.9624899625778198%, top4=0.9769899845123291%, top5=0.9848799705505371%, loss=0.03213225769460201, time=1377.370038509369s\n",
      "Train epoch 385: top1=0.8392499685287476%, top2=0.9326199889183044%, top3=0.9635699987411499%, top4=0.9771699905395508%, top5=0.9851199984550476%, loss=0.031906708146417516, time=1375.7065267562866s\n",
      "Train epoch 386: top1=0.8376500010490417%, top2=0.9320099949836731%, top3=0.9627599716186523%, top4=0.9770099520683289%, top5=0.9841699600219727%, loss=0.032153491319194434, time=1378.9922280311584s\n",
      "Train epoch 387: top1=0.838189959526062%, top2=0.9322800040245056%, top3=0.9631199836730957%, top4=0.976859986782074%, top5=0.9844599962234497%, loss=0.03193931596936658, time=1379.1450350284576s\n",
      "Train epoch 388: top1=0.8341799974441528%, top2=0.9319199919700623%, top3=0.9624099731445312%, top4=0.9766299724578857%, top5=0.9843899607658386%, loss=0.03256617602481507, time=1376.3070142269135s\n",
      "Train epoch 389: top1=0.8357899785041809%, top2=0.9305699467658997%, top3=0.9615799784660339%, top4=0.9762099981307983%, top5=0.9847699999809265%, loss=0.03246355404854752, time=1376.6894965171814s\n",
      "Train epoch 390: top1=0.8388699889183044%, top2=0.9327999949455261%, top3=0.9643099904060364%, top4=0.9774999618530273%, top5=0.9848799705505371%, loss=0.031689818198571446, time=1376.7414202690125s\n",
      "Train epoch 391: top1=0.8398500084877014%, top2=0.9334099888801575%, top3=0.9640100002288818%, top4=0.9778199791908264%, top5=0.9853299856185913%, loss=0.03174583427906968, time=1376.9060838222504s\n",
      "Train epoch 392: top1=0.835919976234436%, top2=0.9323999881744385%, top3=0.963409960269928%, top4=0.977429986000061%, top5=0.9850199818611145%, loss=0.031977892134580764, time=1378.5066170692444s\n",
      "Train epoch 393: top1=0.8390899896621704%, top2=0.9335599541664124%, top3=0.9642099738121033%, top4=0.9780399799346924%, top5=0.9855499863624573%, loss=0.031393695522258055, time=1378.6264729499817s\n",
      "Train epoch 394: top1=0.8402899503707886%, top2=0.9335999488830566%, top3=0.9645899534225464%, top4=0.9779199957847595%, top5=0.985539972782135%, loss=0.03145250674713403, time=1378.754442691803s\n",
      "Train epoch 395: top1=0.8402799963951111%, top2=0.9344799518585205%, top3=0.9649399518966675%, top4=0.9784299731254578%, top5=0.9860599637031555%, loss=0.03121276335415896, time=1376.8538823127747s\n",
      "Train epoch 396: top1=0.8384199738502502%, top2=0.9332199692726135%, top3=0.9641499519348145%, top4=0.9778299927711487%, top5=0.9855799674987793%, loss=0.031760703855725006, time=1376.942547082901s\n",
      "Train epoch 397: top1=0.8396099805831909%, top2=0.9337499737739563%, top3=0.9639699459075928%, top4=0.977649986743927%, top5=0.9850199818611145%, loss=0.031605779027361426, time=1377.6494603157043s\n",
      "Train epoch 398: top1=0.8363699913024902%, top2=0.9312899708747864%, top3=0.9625699520111084%, top4=0.9772799611091614%, top5=0.9846499562263489%, loss=0.03234118779404089, time=1387.4949073791504s\n",
      "Train epoch 399: top1=0.837369978427887%, top2=0.9321199655532837%, top3=0.9629499912261963%, top4=0.9773199558258057%, top5=0.9846400022506714%, loss=0.03202795561814681, time=1376.7283263206482s\n",
      "Train epoch 400: top1=0.8389599919319153%, top2=0.9328399896621704%, top3=0.9634299874305725%, top4=0.9778099656105042%, top5=0.9850199818611145%, loss=0.031766125644799324, time=1377.2229442596436s\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "num_parameters = count_parameters(model)\n",
    "print(f'This Model has {num_parameters} parameters')\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "\n",
    "# Define train and test functions (use examples)\n",
    "def train_epoch(loader, epoch):\n",
    "    model.train()\n",
    "\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    correct = {1:0.0, 2:0.0, 3:0.0, 4:0.0, 5:0.0} # set the initial correct count for top1-to-top5 accuracy\n",
    "\n",
    "    for i, (inputs, targets) in enumerate(loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        accuracies = topk_accuracy(outputs, targets, topk=(1, 2, 3, 4, 5))\n",
    "        for k in accuracies:\n",
    "            correct[k] += accuracies[k]['correct']\n",
    "        # print(f'batch{i} done!')\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    top1_acc, top2_acc, top3_acc, top4_acc, top5_acc = [(correct[k]/len(loader.dataset)) for k in correct]\n",
    "    avg_loss = running_loss / len(loader.dataset)\n",
    "\n",
    "    report_train = f'Train epoch {epoch}: top1={top1_acc}%, top2={top2_acc}%, top3={top3_acc}%, top4={top4_acc}%, top5={top5_acc}%, loss={avg_loss}, time={elapsed_time}s'\n",
    "    print(report_train)\n",
    "\n",
    "    return report_train\n",
    "\n",
    "def test_epoch(loader, epoch):\n",
    "    model.eval()\n",
    "\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    correct = {1:0.0, 2:0.0, 3:0.0, 4:0.0, 5:0.0} # set the initial correct count for top1-to-top5 accuracy\n",
    "\n",
    "    for _, (inputs, targets) in enumerate(loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        accuracies = topk_accuracy(outputs, targets, topk=(1, 2, 3, 4, 5))\n",
    "        for k in accuracies:\n",
    "            correct[k] += accuracies[k]['correct']\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    top1_acc, top2_acc, top3_acc, top4_acc, top5_acc = [(correct[k]/len(loader.dataset)) for k in correct]\n",
    "    avg_loss = running_loss / len(loader.dataset)\n",
    "\n",
    "    report_test = f'Test epoch {epoch}: top1={top1_acc}%, top2={top2_acc}%, top3={top3_acc}%, top4={top4_acc}%, top5={top5_acc}%, loss={avg_loss}, time={elapsed_time}s'\n",
    "    print(report_test)\n",
    "\n",
    "    return report_test\n",
    "\n",
    "# Set up the directories to save the results\n",
    "result_dir = os.path.join('../results', TEST_ID)\n",
    "result_subdir = os.path.join(result_dir, 'accuracy_stats')\n",
    "model_subdir = os.path.join(result_dir, 'model_stats')\n",
    "\n",
    "os.makedirs(result_subdir, exist_ok=True)\n",
    "os.makedirs(model_subdir, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(result_dir, 'model_stats', 'model_info.txt'), 'a') as f:\n",
    "    f.write(f'total number of parameters:\\n{num_parameters}')\n",
    "\n",
    "# Train from Scratch - Just Train\n",
    "print(f'Training for {len(range(n_epoch))} epochs\\n')\n",
    "for epoch in range(0+1,n_epoch+1):\n",
    "    report_train = train_epoch(train_loader, epoch)\n",
    "    # report_test = test_epoch(test_loader, epoch)\n",
    "\n",
    "    report = report_train + '\\n' #+ report_test + '\\n\\n'\n",
    "    if epoch % 5 == 0:\n",
    "        model_path = os.path.join(result_dir, 'model_stats', f'Model_epoch_{epoch}.pth')\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "    with open(os.path.join(result_dir, 'accuracy_stats', 'report_train.txt'), 'a') as f:\n",
    "        f.write(report)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
