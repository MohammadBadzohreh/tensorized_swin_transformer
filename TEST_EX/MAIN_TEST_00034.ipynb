{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "import os\n",
    "# convolution patch embedding\n",
    "# from Tensorized_components.patch_embedding  import Patch_Embedding        \n",
    "from Tensorized_components.tcl_patch_embedding  import  PatchEmbedding  as  Patch_Embedding      \n",
    "from Tensorized_components.w_msa_w_o_b_sign  import WindowMSA     \n",
    "from Tensorized_components.sh_wmsa_w_o_b_sign import ShiftedWindowMSA     \n",
    "from Tensorized_components.patch_merging  import TensorizedPatchMerging  \n",
    "from Tensorized_Layers.TCL_CHANGED import TCL_CHANGED   \n",
    "from Tensorized_Layers.TRL import TRL   \n",
    "from Utils.Accuracy_measures import topk_accuracy\n",
    "from Utils.TinyImageNet_loader import get_tinyimagenet_dataloaders\n",
    "from Utils.Num_parameter import count_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinBlock1(nn.Module):\n",
    "    \"\"\"\n",
    "    A class representing 'Block 1' in your Swin Transformer.\n",
    "    This captures the sequence of:\n",
    "        (1) Window MSA + residual\n",
    "        (2) TCL + residual\n",
    "        (3) Shifted Window MSA + residual\n",
    "        (4) TCL + residual\n",
    "    but only for the first blockâ€™s hyperparameters and submodules.\n",
    "    \"\"\"\n",
    "    def __init__(self, w_msa, sw_msa, trl1,trl2,trl3,trl4, embed_shape, dropout=0):\n",
    "        super(SwinBlock1, self).__init__()\n",
    "        # Typically each sub-layer has its own LayerNorm\n",
    "        self.norm1 = nn.LayerNorm(embed_shape)\n",
    "        self.norm2 = nn.LayerNorm(embed_shape)\n",
    "        self.norm3 = nn.LayerNorm(embed_shape)\n",
    "        self.norm4 = nn.LayerNorm(embed_shape)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # We pass in pre-built modules (WindowMSA, ShiftedWindowMSA, TCL)\n",
    "        self.w_msa = w_msa\n",
    "        self.sw_msa = sw_msa\n",
    "        self.trl1 = trl1\n",
    "        self.gelu = nn.GELU()\n",
    "        self.trl2 = trl2\n",
    "        self.trl3 = trl3\n",
    "        self.trl4 = trl4\n",
    "    def forward(self, x):\n",
    "        # ----- First Window MSA + Residual -----\n",
    "        x_res = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.dropout(self.w_msa(x))\n",
    "        x = x + x_res\n",
    "\n",
    "        # ----- TCL + Residual -----\n",
    "        x_res = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.trl1(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.trl2(x)\n",
    "        x = x + x_res\n",
    "\n",
    "        # ----- Shifted Window MSA + Residual -----\n",
    "        x_res = x\n",
    "        x = self.norm3(x)\n",
    "        x = self.dropout(self.sw_msa(x))\n",
    "        x = x + x_res\n",
    "\n",
    "        # ----- TCL + Residual -----\n",
    "        x_res = x\n",
    "        x = self.norm4(x)\n",
    "        x = self.trl3(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.trl4(x)\n",
    "        x = x + x_res\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinBlock2(nn.Module):\n",
    "    def __init__(self, w_msa, sw_msa, trl1, trl2 , trl3 , trl4,  embed_shape=(4,4,6), dropout=0):\n",
    "        super(SwinBlock2, self).__init__()\n",
    "        # LN layers\n",
    "        self.norm1 = nn.LayerNorm(embed_shape)\n",
    "        self.norm2 = nn.LayerNorm(embed_shape)\n",
    "        self.norm3 = nn.LayerNorm(embed_shape)\n",
    "        self.norm4 = nn.LayerNorm(embed_shape)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.w_msa = w_msa\n",
    "        self.sw_msa = sw_msa\n",
    "        self.trl1 = trl1\n",
    "        self.trl2 = trl2\n",
    "        self.trl3 = trl3\n",
    "        self.trl4 = trl4\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Window MSA\n",
    "        x_res = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.dropout(self.w_msa(x))\n",
    "        x = x + x_res\n",
    "\n",
    "        # TCL\n",
    "        x_res = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.trl1(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.trl2(x)\n",
    "        x = x + x_res\n",
    "\n",
    "        # Shifted Window MSA\n",
    "        x_res = x\n",
    "        x = self.norm3(x)\n",
    "        x = self.dropout(self.sw_msa(x))\n",
    "        x = x + x_res\n",
    "\n",
    "        # TCL\n",
    "        x_res = x\n",
    "        x = self.norm4(x)\n",
    "        x = self.trl3(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.trl4(x)\n",
    "        x = x + x_res\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinBlock3(nn.Module):\n",
    "    def __init__(self, w_msa, sw_msa, trl1,  trl2 , trl3 , trl4,   embed_shape=(4,4,12), dropout=0):\n",
    "        super(SwinBlock3, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(embed_shape)\n",
    "        self.norm2 = nn.LayerNorm(embed_shape)\n",
    "        self.norm3 = nn.LayerNorm(embed_shape)\n",
    "        self.norm4 = nn.LayerNorm(embed_shape)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.w_msa = w_msa\n",
    "        self.sw_msa = sw_msa\n",
    "        self.trl1 = trl1\n",
    "        self.gelu = nn.GELU()\n",
    "        self.trl2 = trl2\n",
    "        self.trl3 = trl3\n",
    "        self.trl4 = trl4\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_res = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.dropout(self.w_msa(x))\n",
    "        x = x + x_res\n",
    "\n",
    "        x_res = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.trl1(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.trl2(x)\n",
    "        x = x + x_res\n",
    "\n",
    "        x_res = x\n",
    "        x = self.norm3(x)\n",
    "        x = self.dropout(self.sw_msa(x))\n",
    "        x = x + x_res\n",
    "\n",
    "        x_res = x\n",
    "        x = self.norm4(x)\n",
    "        x = self.trl3(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.trl4(x)\n",
    "        x = x + x_res\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinBlock4(nn.Module):\n",
    "    def __init__(self, w_msa, sw_msa, trl1, trl2 , trl3 , trl4 ,  embed_shape=(4,4,24), dropout=0):\n",
    "        super(SwinBlock4, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(embed_shape)\n",
    "        self.norm2 = nn.LayerNorm(embed_shape)\n",
    "        self.norm3 = nn.LayerNorm(embed_shape)\n",
    "        self.norm4 = nn.LayerNorm(embed_shape)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.w_msa = w_msa\n",
    "        self.sw_msa = sw_msa\n",
    "        self.trl1 = trl1\n",
    "        self.trl2 = trl2\n",
    "        self.trl3 = trl3\n",
    "        self.trl4 = trl4\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_res = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.dropout(self.w_msa(x))\n",
    "        x = x + x_res\n",
    "\n",
    "        x_res = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.trl1(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.trl2(x)\n",
    "        x = x + x_res\n",
    "\n",
    "        x_res = x\n",
    "        x = self.norm3(x)\n",
    "        x = self.dropout(self.sw_msa(x))\n",
    "        x = x + x_res\n",
    "\n",
    "        x_res = x\n",
    "        x = self.norm4(x)\n",
    "        x = self.trl3(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.trl4(x)\n",
    "        x = x + x_res\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 img_size=224,\n",
    "                 patch_size=4,\n",
    "                 in_chans=3,\n",
    "                 embed_shape=(4,4,12),\n",
    "                 bias=True,\n",
    "                 dropout=0,\n",
    "                 device=\"cuda\"):\n",
    "        super(SwinTransformer, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "# tcl patch embedding \n",
    "\n",
    "\n",
    "# TODO : change batch size and device to cuda\n",
    "        self.patch_embedding = Patch_Embedding(\n",
    "            input_size=(16,3,224,224),\n",
    "            patch_size=patch_size,\n",
    "            embed_dim=embed_shape,\n",
    "            bias=bias,\n",
    "            device=\"cpu\",\n",
    "            ignore_modes = (0,1,2)\n",
    "        )\n",
    "# convolution \n",
    "        # self.patch_embedding = Patch_Embedding(\n",
    "        #     img_size=img_size,\n",
    "        #     patch_size=patch_size,\n",
    "        #     in_chans=in_chans,\n",
    "        #     embed_shape=embed_shape,\n",
    "        #     bias=bias\n",
    "        # )\n",
    "\n",
    "        # -------------------------------- block 1 --------------------------\n",
    "\n",
    "        self.w_msa_1 = WindowMSA(\n",
    "            window_size=7,\n",
    "            embed_dims=embed_shape,\n",
    "            rank_window=embed_shape,\n",
    "            head_factors=(1,2,3),\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        self.sw_msa_1 = ShiftedWindowMSA(\n",
    "            window_size=7,\n",
    "            embed_dims=embed_shape,\n",
    "            rank_window=embed_shape,\n",
    "            head_factors=(1,2,3),\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "\n",
    "    # def __init__(self, input_size, output, rank, ignore_modes = (0,), bias = True, device = 'cuda'):\n",
    "\n",
    "        self.trl_1 = TRL(\n",
    "            input_size=(16, 56, 56, 4,4,12),\n",
    "            output=(4,4,48),\n",
    "            rank=(4,4,12,4,4,48),\n",
    "            ignore_modes=(0, 1, 2),\n",
    "            bias=bias,\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        self.trl_1_2 = TRL(\n",
    "            input_size=(16, 56, 56, 4,4,48),\n",
    "            output=(4,4,12),\n",
    "            rank=(4,4,48,4,4,12),\n",
    "            ignore_modes=(0, 1, 2),\n",
    "            bias=bias,\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        self.trl_1_3 = TRL(\n",
    "            input_size=(16, 56, 56, 4,4,12),\n",
    "            output=(4,4,48),\n",
    "            rank=(4,4,12,4,4,48),\n",
    "            ignore_modes=(0, 1, 2),\n",
    "            bias=bias,\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        self.trl_1_4 = TRL(\n",
    "            input_size=(16, 56, 56, 4,4,48),\n",
    "            output=(4,4,12),\n",
    "            rank=(4,4,48,4,4,12),\n",
    "            ignore_modes=(0, 1, 2),\n",
    "            bias=bias,\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "\n",
    "        self.block1_list = nn.ModuleList([\n",
    "            SwinBlock1(\n",
    "                w_msa=self.w_msa_1,\n",
    "                sw_msa=self.sw_msa_1,\n",
    "                trl1=self.trl_1,\n",
    "                trl2 = self.trl_1_2,\n",
    "                trl3 = self.trl_1_3,\n",
    "                trl4 = self.trl_1_4,\n",
    "                embed_shape=embed_shape,\n",
    "                dropout=dropout\n",
    "            )\n",
    "            for _ in range(2)\n",
    "        ])\n",
    "\n",
    "        # -------------------------------- block 2 --------------------------\n",
    "\n",
    "\n",
    "        self.patch_merging_1 = TensorizedPatchMerging(\n",
    "            input_size=(16, 56, 56, 4,4,12),\n",
    "            in_embed_shape=embed_shape,\n",
    "            out_embed_shape=(4,4,24),\n",
    "            bias=bias,\n",
    "            ignore_modes=(0, 1, 2),\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        self.w_msa_2 = WindowMSA(\n",
    "            window_size=7,\n",
    "            embed_dims=(4,4,24),\n",
    "            rank_window=(4,4,24),\n",
    "            head_factors=(1,2,6),\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        self.sw_msa_2 = ShiftedWindowMSA(\n",
    "            window_size=7,\n",
    "            embed_dims=(4,4,24),\n",
    "            rank_window=(4,4,24),\n",
    "            head_factors=(1,2,6),\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        self.trl_2 = TRL(\n",
    "            input_size=(16, 28, 28, 4,4,24),\n",
    "            output=(4,4,96),\n",
    "            rank=(4,4,24,4,4,96),\n",
    "            ignore_modes=(0, 1, 2),\n",
    "            bias=bias,\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "\n",
    "        self.trl_2_2 = TRL(\n",
    "            input_size=(16, 28, 28, 4,4,96),\n",
    "            output=(4,4,24),\n",
    "            rank=(4,4,96,4,4,24),\n",
    "            ignore_modes=(0, 1, 2),\n",
    "            bias=bias,\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        self.trl_2_3 = TRL(\n",
    "            input_size=(16, 28, 28, 4,4,24),\n",
    "            output=(4,4,96),\n",
    "            rank=(4,4,24,4,4,96),\n",
    "            ignore_modes=(0, 1, 2),\n",
    "            bias=bias,\n",
    "            device=self.device\n",
    "        )\n",
    "        \n",
    "        self.trl_2_4 = TRL(\n",
    "            input_size=(16, 28, 28, 4,4,96),\n",
    "            output=(4,4,24),\n",
    "            rank=(4,4,96,4,4,24),\n",
    "            ignore_modes=(0, 1, 2),\n",
    "            bias=bias,\n",
    "            device=self.device\n",
    "        )\n",
    "        # We repeat Block2 two times\n",
    "        self.block2_list = nn.ModuleList([\n",
    "            SwinBlock2(\n",
    "                w_msa=self.w_msa_2,\n",
    "                sw_msa=self.sw_msa_2,\n",
    "                trl1=self.trl_2,\n",
    "                trl2 = self.trl_2_2,\n",
    "                trl3 = self.trl_2_3,\n",
    "                trl4 = self.trl_2_4,\n",
    "                embed_shape=(4,4,24),  \n",
    "                dropout=dropout\n",
    "            )\n",
    "            for _ in range(2)\n",
    "        ])\n",
    "\n",
    "\n",
    "        # # -------------------------------- block 3 --------------------------\n",
    "\n",
    "        self.patch_merging_2 = TensorizedPatchMerging(\n",
    "            input_size=(16, 28, 28, 4,4,24),\n",
    "            in_embed_shape=(4,4,24),\n",
    "            out_embed_shape=(4,4,48),\n",
    "            bias=bias,\n",
    "            ignore_modes=(0, 1, 2),\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "\n",
    "        self.w_msa_3 = WindowMSA(\n",
    "            window_size=7,\n",
    "            embed_dims=(4,4,48),\n",
    "            rank_window=(4,4,48),\n",
    "            head_factors=(2,1,12),\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        self.sw_msa_3 = ShiftedWindowMSA(\n",
    "            window_size=7,\n",
    "            embed_dims=(4,4,48),\n",
    "            rank_window=(4,4,48),\n",
    "            head_factors=(2,1,12),\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "\n",
    "        self.trl_3 = TRL(\n",
    "            input_size=(16, 14, 14, 4,4,48),\n",
    "            output=(4,4,192),\n",
    "            rank=(4,4,48,4,4,192),\n",
    "            ignore_modes=(0, 1, 2),\n",
    "            bias=bias,\n",
    "            device=self.device\n",
    "        )\n",
    "        self.trl_3_2 = TRL(\n",
    "            input_size=(16, 14, 14, 4,4,192),\n",
    "            output=(4,4,48),\n",
    "            rank=(4,4,192 ,4,4,48),\n",
    "            ignore_modes=(0, 1, 2),\n",
    "            bias=bias,\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        self.trl_3_3 = TRL(\n",
    "            input_size=(16, 14, 14, 4,4,48),\n",
    "            output=(4,4,192),\n",
    "            rank=(4,4,48,4,4,192),\n",
    "            ignore_modes=(0, 1, 2),\n",
    "            bias=bias,\n",
    "            device=self.device\n",
    "        )\n",
    "        self.trl_3_4 = TRL(\n",
    "            input_size=(16, 14, 14, 4,4,192),\n",
    "            output=(4,4,48),\n",
    "            rank=(4,4,192 ,4,4,48),\n",
    "            ignore_modes=(0, 1, 2),\n",
    "            bias=bias,\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "\n",
    "        # Repeat Block3 6 times\n",
    "        self.block3_list = nn.ModuleList([\n",
    "            SwinBlock3(\n",
    "                w_msa=self.w_msa_3,\n",
    "                sw_msa=self.sw_msa_3,\n",
    "                trl1=self.trl_3,\n",
    "                trl2=self.trl_3_2,\n",
    "                trl3=self.trl_3_3,\n",
    "                trl4=self.trl_3_4,\n",
    "                embed_shape=(4,4,48),\n",
    "                dropout=dropout\n",
    "            )\n",
    "            for _ in range(18)\n",
    "        ])\n",
    "\n",
    "        # # # -------------------------------- block 4 --------------------------\n",
    "\n",
    "        self.patch_merging_3 = TensorizedPatchMerging(\n",
    "            input_size=(16, 14, 14, 4,4,48),\n",
    "            in_embed_shape=(4,4,48),\n",
    "            out_embed_shape=(4,4,96),\n",
    "            bias=bias,\n",
    "            ignore_modes=(0, 1, 2),\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        self.w_msa_4 = WindowMSA(\n",
    "            window_size=7,\n",
    "            embed_dims=(4,4,96),\n",
    "            rank_window=(4,4,96),\n",
    "            head_factors=(2,1,24),\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        self.sw_msa_4 = ShiftedWindowMSA(\n",
    "            window_size=7,\n",
    "            embed_dims=(4,4,96),\n",
    "            rank_window=(4,4,96),\n",
    "            head_factors=(2,1,24),\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "\n",
    "        self.trl_4 = TRL(\n",
    "            input_size=(16, 7, 7, 4,4,96),\n",
    "            output=(4,4,384),\n",
    "            rank=(4,4,96,4,4,384),\n",
    "            ignore_modes=(0, 1, 2),\n",
    "            bias=bias,\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        self.trl_4_2 = TRL(\n",
    "            input_size=(16, 7, 7, 4,4,384),\n",
    "            output = (4,4,96),\n",
    "            rank=(4,4,384,4,4,96),\n",
    "            ignore_modes=(0, 1, 2),\n",
    "            bias=bias,\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "\n",
    "        self.trl_4_3 = TRL(\n",
    "            input_size=(16, 7, 7, 4,4,96),\n",
    "            output=(4,4,384),\n",
    "            rank=(4,4,96,4,4,384),\n",
    "            ignore_modes=(0, 1, 2),\n",
    "            bias=bias,\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "\n",
    "        self.trl_4_4 = TRL(\n",
    "            input_size=(16, 7, 7, 4,4,384),\n",
    "            output = (4,4,96),\n",
    "            rank=(4,4,384,4,4,96),\n",
    "            ignore_modes=(0, 1, 2),\n",
    "            bias=bias,\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        self.block4_list = nn.ModuleList([\n",
    "            SwinBlock4(\n",
    "                w_msa=self.w_msa_4,\n",
    "                sw_msa=self.sw_msa_4,\n",
    "                trl1=self.trl_4,\n",
    "                trl2=self.trl_4_2,\n",
    "                trl3=self.trl_4_3,\n",
    "                trl4=self.trl_4_4,\n",
    "                embed_shape=(4,4,96),\n",
    "                dropout=dropout\n",
    "            )\n",
    "            for _ in range(2)\n",
    "        ])\n",
    "\n",
    "        # -------------------------------- classifier --------------------------\n",
    "\n",
    "    \n",
    "\n",
    "        self.classifier = TRL(input_size=(16,4,4,96),\n",
    "                            output=(200,),\n",
    "                            rank=(4,4,96,200),\n",
    "                            ignore_modes=(0,),\n",
    "                            bias=bias,\n",
    "                            device=self.device) \n",
    "        \n",
    "\n",
    "        # positoin embedding\n",
    "\n",
    "\n",
    "        self.pos_embedding = nn.Parameter(\n",
    "            torch.randn(1,\n",
    "                        56,\n",
    "                        56,\n",
    "                        4,\n",
    "                        4,\n",
    "                        12,\n",
    "                        device = self.device\n",
    "                        ), requires_grad=True)\n",
    "\n",
    "    def forward(self, x):\n",
    " \n",
    "\n",
    "        x = self.patch_embedding(x)\n",
    "\n",
    "        x += self.pos_embedding\n",
    "\n",
    "        for i, blk in enumerate(self.block1_list, 1):\n",
    "            x = blk(x)\n",
    "\n",
    "\n",
    "        x = self.patch_merging_1(x)\n",
    "\n",
    "\n",
    "\n",
    "        for i, blk in enumerate(self.block2_list, 1):\n",
    "            x = blk(x)\n",
    "\n",
    "\n",
    "        x = self.patch_merging_2(x)\n",
    "\n",
    "        for i, blk in enumerate(self.block3_list, 1):\n",
    "            x = blk(x)\n",
    "\n",
    "\n",
    "        x = self.patch_merging_3(x)\n",
    "\n",
    "\n",
    "        for i, blk in enumerate(self.block4_list, 1):\n",
    "            x = blk(x)\n",
    "\n",
    "\n",
    "        x = x.mean(dim=(1, 2))\n",
    "\n",
    "        output = self.classifier(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is set to : cpu\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Setup the device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'\n",
    "print(f'Device is set to : {device}')\n",
    "\n",
    "# Configs\n",
    "\n",
    "TEST_ID = 'Test_ID00034'\n",
    "batch_size = 16\n",
    "n_epoch = 400\n",
    "image_size = 224\n",
    "\n",
    "model = SwinTransformer(img_size=224,patch_size=4,in_chans=3,embed_shape=(4,4,12),bias=True,device=device).to(device)\n",
    "\n",
    "\n",
    "# Set up the transforms and train/test loaders\n",
    "\n",
    "tiny_transform_train = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Resize((image_size, image_size)), \n",
    "        transforms.RandomCrop(image_size, padding=5),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])\n",
    "tiny_transform_val = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])\n",
    "tiny_transform_test = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])\n",
    "\n",
    "\n",
    "train_loader, val_loader , test_loader = get_tinyimagenet_dataloaders(\n",
    "                                                    data_dir = '../datasets',\n",
    "                                                    transform_train=tiny_transform_train,\n",
    "                                                    transform_val=tiny_transform_val,\n",
    "                                                    transform_test=tiny_transform_test,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    image_size=image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Model has 52472588 parameters\n",
      "Training for 400 epochs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_parameters = count_parameters(model)\n",
    "print(f'This Model has {num_parameters} parameters')\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "\n",
    "# Define train and test functions (use examples)\n",
    "def train_epoch(loader, epoch):\n",
    "    model.train()\n",
    "\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    correct = {1:0.0, 2:0.0, 3:0.0, 4:0.0, 5:0.0} # set the initial correct count for top1-to-top5 accuracy\n",
    "\n",
    "    for i, (inputs, targets) in enumerate(loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        accuracies = topk_accuracy(outputs, targets, topk=(1, 2, 3, 4, 5))\n",
    "        for k in accuracies:\n",
    "            correct[k] += accuracies[k]['correct']\n",
    "        # print(f'batch{i} done!')\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    top1_acc, top2_acc, top3_acc, top4_acc, top5_acc = [(correct[k]/len(loader.dataset)) for k in correct]\n",
    "    avg_loss = running_loss / len(loader.dataset)\n",
    "\n",
    "    report_train = f'Train epoch {epoch}: top1={top1_acc}%, top2={top2_acc}%, top3={top3_acc}%, top4={top4_acc}%, top5={top5_acc}%, loss={avg_loss}, time={elapsed_time}s'\n",
    "    print(report_train)\n",
    "\n",
    "    return report_train\n",
    "\n",
    "def test_epoch(loader, epoch):\n",
    "    model.eval()\n",
    "\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    correct = {1:0.0, 2:0.0, 3:0.0, 4:0.0, 5:0.0} # set the initial correct count for top1-to-top5 accuracy\n",
    "\n",
    "    for _, (inputs, targets) in enumerate(loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        accuracies = topk_accuracy(outputs, targets, topk=(1, 2, 3, 4, 5))\n",
    "        for k in accuracies:\n",
    "            correct[k] += accuracies[k]['correct']\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    top1_acc, top2_acc, top3_acc, top4_acc, top5_acc = [(correct[k]/len(loader.dataset)) for k in correct]\n",
    "    avg_loss = running_loss / len(loader.dataset)\n",
    "\n",
    "    report_test = f'Test epoch {epoch}: top1={top1_acc}%, top2={top2_acc}%, top3={top3_acc}%, top4={top4_acc}%, top5={top5_acc}%, loss={avg_loss}, time={elapsed_time}s'\n",
    "    print(report_test)\n",
    "\n",
    "    return report_test\n",
    "\n",
    "# Set up the directories to save the results\n",
    "result_dir = os.path.join('../results', TEST_ID)\n",
    "result_subdir = os.path.join(result_dir, 'accuracy_stats')\n",
    "model_subdir = os.path.join(result_dir, 'model_stats')\n",
    "\n",
    "os.makedirs(result_subdir, exist_ok=True)\n",
    "os.makedirs(model_subdir, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(result_dir, 'model_stats', 'model_info.txt'), 'a') as f:\n",
    "    f.write(f'total number of parameters:\\n{num_parameters}')\n",
    "\n",
    "# Train from Scratch - Just Train\n",
    "print(f'Training for {len(range(n_epoch))} epochs\\n')\n",
    "for epoch in range(0+1,n_epoch+1):\n",
    "    report_train = train_epoch(train_loader, epoch)\n",
    "    # report_test = test_epoch(test_loader, epoch)\n",
    "\n",
    "    report = report_train + '\\n' #+ report_test + '\\n\\n'\n",
    "    if epoch % 5 == 0:\n",
    "        model_path = os.path.join(result_dir, 'model_stats', f'Model_epoch_{epoch}.pth')\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "    with open(os.path.join(result_dir, 'accuracy_stats', 'report_train.txt'), 'a') as f:\n",
    "        f.write(report)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
