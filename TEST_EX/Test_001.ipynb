{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from Tensorized_components.patch_embedding  import Patch_Embedding     \n",
    "from Tensorized_components.w_msa  import WindowMSA     \n",
    "from Tensorized_components.sh_wmsa  import ShiftedWindowMSA     \n",
    "from Tensorized_components.patch_merging  import TensorizedPatchMerging  \n",
    "from Tensorized_Layers.TCL_CHANGED import TCL_CHANGED   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add device compatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from Tensorized_components.patch_embedding  import Patch_Embedding     \n",
    "from Tensorized_components.w_msa  import WindowMSA     \n",
    "from Tensorized_components.sh_wmsa  import ShiftedWindowMSA     \n",
    "from Tensorized_components.patch_merging  import TensorizedPatchMerging  \n",
    "from Tensorized_Layers.TCL_CHANGED import TCL_CHANGED   \n",
    "\n",
    "\n",
    "class SwinTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 img_size=224,\n",
    "                 patch_size=4,\n",
    "                 in_chans=3,\n",
    "                 embed_shape=(4,4,3),\n",
    "                 bias=True,\n",
    "                 dropout=0.5,\n",
    "                 device=\"cpu\"):\n",
    "        super(SwinTransformer, self).__init__()\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(embed_shape)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "        self.patch_embedding = Patch_Embedding(img_size=img_size,\n",
    "                                                patch_size=patch_size,\n",
    "                                                in_chans=in_chans,\n",
    "                                                embed_shape=embed_shape,\n",
    "                                                bias=bias)\n",
    "    \n",
    "        \n",
    "\n",
    "        self.w_msa_1 = WindowMSA(window_size=7, embed_dims=(4, 4, 3),\n",
    "                    rank_window=(4,4,3), head_factors=(2,2,1), device=device).to(device)\n",
    "        \n",
    "        self.sw_msa_1 = ShiftedWindowMSA(\n",
    "            window_size=7,embed_dims=(4, 4, 3),rank_window=(4, 4, 3),head_factors=(2, 2, 1),device='cpu')\n",
    "    \n",
    "        self.patch_merging_1 = TensorizedPatchMerging(\n",
    "        input_size=(16,56, 56, 4, 4, 3),\n",
    "        in_embed_shape=embed_shape,\n",
    "        out_embed_shape=(4,4,6),   \n",
    "        bias=bias,\n",
    "        ignore_modes=(0,1,2),\n",
    "        device=device).to(device)\n",
    "\n",
    "        self.tcl_1 = TCL_CHANGED(\n",
    "            input_size=(1, 56, 56, 4, 4, 3),  # Example shape after ignoring batch dim\n",
    "            rank=(4, 4, 3),\n",
    "            ignore_modes=(0, 1, 2),\n",
    "            bias=True,\n",
    "            device='cpu'\n",
    "        )\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # stage 1\n",
    "        patches = self.patch_embedding(x)\n",
    "        print(\"data size after patch\",patches.shape)\n",
    "\n",
    "        # wmsa_1\n",
    "\n",
    "        x_res = patches\n",
    "        x = self.norm1(patches)\n",
    "        x = self.dropout(self.w_msa_1(x))\n",
    "        x = x + x_res\n",
    "\n",
    "\n",
    "        x_res = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.tcl_1(x)\n",
    "        x = x + x_res\n",
    "\n",
    "        x_res = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.dropout(self.sw_msa_1(x))\n",
    "        x = x + x_res\n",
    "\n",
    "        x_res = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.tcl_1(x)\n",
    "        x = x + x_res\n",
    "\n",
    "        print(\"shape of x is\",  x.shape)\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # x_res = patches\n",
    "\n",
    "        # print(\"shape of patches is \",patches.shape)\n",
    "\n",
    "        # x = self.norm1(patches + self.dropout(self.w_msa_1(patches)))\n",
    "\n",
    "        # print(\"shape after window attention\",x.shape)\n",
    "        # wmsa_1 = x + x_res\n",
    "\n",
    "        # sh_wmsa_1\n",
    "\n",
    "        # print(\"output wmsa stage 1\" , wmsa_1.shape)\n",
    "\n",
    "\n",
    "        # end stage 1\n",
    "\n",
    "        # patch_merginig_1 = self.patch_merging_1(wmsa_1)\n",
    "\n",
    "        # print(\"patch merging\",patch_merginig_1.shape)\n",
    "\n",
    "\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shift_size is 3\n",
      "data size after patch torch.Size([1, 56, 56, 4, 4, 3])\n",
      "shape of attention flat is torch.Size([1, 8, 8, 2, 2, 1, 49, 49])\n",
      "shape of bias is torch.Size([1, 1, 1, 2, 2, 1, 49, 49])\n",
      "attention flat after add bias torch.Size([1, 8, 8, 2, 2, 1, 49, 49])\n",
      "shape of mask is torch.Size([1, 8, 8, 1, 1, 1, 49, 49])\n",
      "attn_flat shape afeter add to the mask torch.Size([1, 8, 8, 2, 2, 1, 49, 49])\n",
      "shift size in reverse 3\n",
      "shape of x is torch.Size([1, 56, 56, 4, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a dummy input tensor (batch_size=1, channels=3, height=224, width=224)\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Initialize the model\n",
    "model = SwinTransformer(img_size=224,patch_size=4,in_chans=3,embed_shape=(4,4,3),bias=True,device=\"cpu\")\n",
    "\n",
    "# Forward pass\n",
    "output = model(dummy_input)\n",
    "\n",
    "# Output shape\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor shape: torch.Size([1, 8, 8, 1, 1, 1])\n",
      "Partitioned windows shape: torch.Size([1, 2, 2, 4, 4, 1, 1, 1])\n",
      "Partitioned windows shape: tensor([[18, 19, 20, 21],\n",
      "        [26, 27, 28, 29],\n",
      "        [34, 35, 36, 37],\n",
      "        [42, 43, 44, 45]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from Tensorized_components.Shifted_window_partition  import ShiftedWindowPartition     \n",
    "from Tensorized_components.sh_wmsa  import ShiftedWindowMSA\n",
    "\n",
    "\n",
    "x = torch.arange(64).reshape(1, 8, 8, 1, 1, 1)\n",
    "\n",
    "# Create a sample tensor with shape (B, H, W, C)\n",
    "# B, H, W, C = 1, 8, 8, 3  # Ensure H and W are divisible by the window_size.\n",
    "# x = torch.arange(B * H * W * C, dtype=torch.float32).reshape(B, H, W, C)\n",
    "print(\"Original tensor shape:\", x.shape)\n",
    "\n",
    "# Set the window size and shift size\n",
    "window_size = 4\n",
    "shift_size = 2\n",
    "\n",
    "# Instantiate the ShiftedWindowPartition module.\n",
    "shifted_window_partition = ShiftedWindowPartition(window_size, shift_size)\n",
    "\n",
    "# Partition the tensor with a spatial shift.\n",
    "windows = shifted_window_partition(x)\n",
    "print(\"Partitioned windows shape:\", windows.shape)\n",
    "print(\"Partitioned windows shape:\", windows[0,0,0,:,:,0,0,0])\n",
    "\n",
    "# Reverse the window partition operation to reconstruct the original tensor.\n",
    "# x_reconstructed = shifted_window_partition.reverse(windows, H, W)\n",
    "# print(\"Reconstructed tensor shape:\", x_reconstructed.shape)\n",
    "\n",
    "    # Verify that the reconstruction matches the original tensor.\n",
    "    # if torch.allclose(x, x_reconstructed):\n",
    "        # print(\"Success: The reconstructed tensor matches the original tensor.\")\n",
    "    # else:\n",
    "        # print(\"Error: The reconstructed tensor does not match the original tensor.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shift_size is 3\n",
      "shape of attention flat is torch.Size([1, 8, 8, 2, 2, 1, 49, 49])\n",
      "shape of bias is torch.Size([1, 1, 1, 2, 2, 1, 49, 49])\n",
      "attention flat after add bias torch.Size([1, 8, 8, 2, 2, 1, 49, 49])\n",
      "shape of mask is torch.Size([1, 8, 8, 1, 1, 1, 49, 49])\n",
      "attn_flat shape afeter add to the mask torch.Size([1, 8, 8, 2, 2, 1, 49, 49])\n",
      "shift size in reverse 3\n"
     ]
    }
   ],
   "source": [
    "# usage\n",
    "device = \"cpu\"\n",
    "x = torch.randn(1, 56, 56, 4, 4, 3, device=device)\n",
    "\n",
    "# Window parameters.\n",
    "window_size = 7\n",
    "# TCL configuration: for each window, input size is (7, 7, 4, 4, 3).\n",
    "# Here, we set rank_window to (4, 4, 3) and head_factors to (2, 2, 1) so that\n",
    "# the number of heads is 2*2*1 = 4.\n",
    "rank_window = (4, 4, 3)\n",
    "head_factors = (2, 2, 1)\n",
    "\n",
    "# Instantiate the W-MSA module.\n",
    "w_msa = ShiftedWindowMSA(window_size=window_size, embed_dims=(4, 4, 3),\n",
    "        rank_window=rank_window, head_factors=head_factors, device=device).to(device)\n",
    "\n",
    "x = w_msa(x)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
